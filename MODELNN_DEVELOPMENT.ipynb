{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62217490-f006-4a6c-88db-5512f1d8b234",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> MÓDULO 9\n",
    "### <span style=\"color: blue;\"> <p style=\"text-align: center;\"> MOMENTO 1 - DESENVOLVIMENTO MODELO <span style=\"color: blue;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0b68b-a237-4614-b3c6-cdfb5d5174fb",
   "metadata": {},
   "source": [
    "**Passo 1** - Começamos por importar as bibliotecas que vamos necessitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9dbca7ea-6546-4415-b33a-1c461763f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Data Partition\n",
    "from sklearn.preprocessing import MinMaxScaler # Data Normalization / Scaling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential # Util para definição das layers\n",
    "from tensorflow.keras.layers import Dense # Serve para aplicar as transformações lineares "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d05e4-82cf-44f5-884a-ca287d711c49",
   "metadata": {},
   "source": [
    "**Passo 2** - Depois importamos os nossos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cb446a4-0fc3-4516-8a5b-616e5f41e4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Manufacturer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Screen",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPU",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OS",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CPU_core",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Screen_Size_cm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CPU_frequency",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RAM_GB",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Storage_GB_SSD",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Weight_kg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Price",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a722ed34-61d5-434e-aaf9-96c2a0a2c6e3",
       "rows": [
        [
         "0",
         "Acer",
         "4",
         "IPS Panel",
         "2",
         "1",
         "5",
         "35.56",
         "1.6",
         "8",
         "256",
         "1.6",
         "978"
        ],
        [
         "1",
         "Dell",
         "3",
         "Full HD",
         "1",
         "1",
         "3",
         "39.624",
         "2.0",
         "4",
         "256",
         "2.2",
         "634"
        ],
        [
         "2",
         "Dell",
         "3",
         "Full HD",
         "1",
         "1",
         "7",
         "39.624",
         "2.7",
         "8",
         "256",
         "2.2",
         "946"
        ],
        [
         "3",
         "Dell",
         "4",
         "IPS Panel",
         "2",
         "1",
         "5",
         "33.782",
         "1.6",
         "8",
         "128",
         "1.22",
         "1244"
        ],
        [
         "4",
         "HP",
         "4",
         "Full HD",
         "2",
         "1",
         "7",
         "39.624",
         "1.8",
         "8",
         "256",
         "1.91",
         "837"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Category</th>\n",
       "      <th>Screen</th>\n",
       "      <th>GPU</th>\n",
       "      <th>OS</th>\n",
       "      <th>CPU_core</th>\n",
       "      <th>Screen_Size_cm</th>\n",
       "      <th>CPU_frequency</th>\n",
       "      <th>RAM_GB</th>\n",
       "      <th>Storage_GB_SSD</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer</td>\n",
       "      <td>4</td>\n",
       "      <td>IPS Panel</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>35.560</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>1.60</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell</td>\n",
       "      <td>3</td>\n",
       "      <td>Full HD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>2.20</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell</td>\n",
       "      <td>3</td>\n",
       "      <td>Full HD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39.624</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>2.20</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell</td>\n",
       "      <td>4</td>\n",
       "      <td>IPS Panel</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>33.782</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP</td>\n",
       "      <td>4</td>\n",
       "      <td>Full HD</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39.624</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>1.91</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer  Category     Screen  GPU  OS  CPU_core  Screen_Size_cm  \\\n",
       "0         Acer         4  IPS Panel    2   1         5          35.560   \n",
       "1         Dell         3    Full HD    1   1         3          39.624   \n",
       "2         Dell         3    Full HD    1   1         7          39.624   \n",
       "3         Dell         4  IPS Panel    2   1         5          33.782   \n",
       "4           HP         4    Full HD    2   1         7          39.624   \n",
       "\n",
       "   CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n",
       "0            1.6       8             256       1.60    978  \n",
       "1            2.0       4             256       2.20    634  \n",
       "2            2.7       8             256       2.20    946  \n",
       "3            1.6       8             128       1.22   1244  \n",
       "4            1.8       8             256       1.91    837  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importação dos dados\n",
    "laptop_pricing = pd.read_csv('C:/Users/RH_VG/Downloads/laptop_pricing_NN_treino.csv')\n",
    "laptop_pricing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03725b6-2df4-4110-a92c-0c2b5c565fe5",
   "metadata": {},
   "source": [
    "**Passo 3** - Seleção INICIAL das variáveis de input que vamos usar no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6c92f15b-6a5f-479d-9489-1faf5853dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_pricingset = laptop_pricing[['GPU','CPU_core', 'RAM_GB', 'Manufacturer','Screen_Size_cm', 'Storage_GB_SSD']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1857f8-f301-41b6-ad23-d49d363f4886",
   "metadata": {},
   "source": [
    "**Passo 4** - Realizamos o pré-processamento de dados (para mais opções, ver módulo 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "51bfc41e-4da3-4ab1-b923-d629d88f8844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPU",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CPU_core",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RAM_GB",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Screen_Size_cm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Storage_GB_SSD",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Manufacturer_Asus",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_Dell",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_HP",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_Huawei",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_Lenovo",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_MSI",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_Razer",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_Samsung",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Manufacturer_Toshiba",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "95ad4893-b938-49c7-9849-245968c3be96",
       "rows": [
        [
         "0",
         "2",
         "5",
         "8",
         "35.56",
         "256",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "1",
         "1",
         "3",
         "4",
         "39.624",
         "256",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "2",
         "1",
         "7",
         "8",
         "39.624",
         "256",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "3",
         "2",
         "5",
         "8",
         "33.782",
         "128",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "4",
         "2",
         "7",
         "8",
         "39.624",
         "256",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPU</th>\n",
       "      <th>CPU_core</th>\n",
       "      <th>RAM_GB</th>\n",
       "      <th>Screen_Size_cm</th>\n",
       "      <th>Storage_GB_SSD</th>\n",
       "      <th>Manufacturer_Asus</th>\n",
       "      <th>Manufacturer_Dell</th>\n",
       "      <th>Manufacturer_HP</th>\n",
       "      <th>Manufacturer_Huawei</th>\n",
       "      <th>Manufacturer_Lenovo</th>\n",
       "      <th>Manufacturer_MSI</th>\n",
       "      <th>Manufacturer_Razer</th>\n",
       "      <th>Manufacturer_Samsung</th>\n",
       "      <th>Manufacturer_Toshiba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>35.560</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>39.624</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>39.624</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>33.782</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>39.624</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GPU  CPU_core  RAM_GB  Screen_Size_cm  Storage_GB_SSD  Manufacturer_Asus  \\\n",
       "0    2         5       8          35.560             256              False   \n",
       "1    1         3       4          39.624             256              False   \n",
       "2    1         7       8          39.624             256              False   \n",
       "3    2         5       8          33.782             128              False   \n",
       "4    2         7       8          39.624             256              False   \n",
       "\n",
       "   Manufacturer_Dell  Manufacturer_HP  Manufacturer_Huawei  \\\n",
       "0              False            False                False   \n",
       "1               True            False                False   \n",
       "2               True            False                False   \n",
       "3               True            False                False   \n",
       "4              False             True                False   \n",
       "\n",
       "   Manufacturer_Lenovo  Manufacturer_MSI  Manufacturer_Razer  \\\n",
       "0                False             False               False   \n",
       "1                False             False               False   \n",
       "2                False             False               False   \n",
       "3                False             False               False   \n",
       "4                False             False               False   \n",
       "\n",
       "   Manufacturer_Samsung  Manufacturer_Toshiba  \n",
       "0                 False                 False  \n",
       "1                 False                 False  \n",
       "2                 False                 False  \n",
       "3                 False                 False  \n",
       "4                 False                 False  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_pricing.dropna(inplace=True)\n",
    "laptop_pricingset = laptop_pricing[['GPU','CPU_core', 'RAM_GB', 'Manufacturer','Screen_Size_cm', 'Storage_GB_SSD']]\n",
    "laptop_dummies = pd.get_dummies(laptop_pricingset, columns=['Manufacturer'], drop_first=True)\n",
    "# ... e outras tarefas de pré-processamento que considerem relevantes\n",
    "\n",
    "laptop_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e188398-8401-45ff-8b43-d24ef790da2e",
   "metadata": {},
   "source": [
    "**Passo 5** - Papel de cada variavel no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a3d60c47-c62e-4f17-bbb1-f552b4e1a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = laptop_dummies\n",
    "y = laptop_pricing[\"Price\"].reset_index(drop=True)\n",
    "X = X.reset_index(drop=True)\n",
    "         # Target (variável a prever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706c025-afaf-4327-b81a-f7e6113a04c5",
   "metadata": {},
   "source": [
    "**Passo 6** - Partição dos dados (para mais opções, ver módulo 3 - Amostragem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6c1db675-98df-4101-b655-04d1a0d20ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos começar por separar os dados de treino (que neste momento inclui os dados de validção) dos dados de teste (vamos considerar 20%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624e9d7-6f98-43c4-a943-1f705e4506f7",
   "metadata": {},
   "source": [
    "**Passo 7** - Min-Max para normalizar para uma escala [0 : 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e19d8e40-3df6-461b-bfab-456e63d2b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "#X_test_scaled = scaler.t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b5559-d95d-44c8-b7ef-72efbd8ba65e",
   "metadata": {},
   "source": [
    "**Passo 7** - Definimos agora a arquitetura da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1183b7e8-23ef-4641-9838-f1562fb730bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RH_VG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "# outra função de ativação muito usada é a 'relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99ce27-5d3a-44ec-897f-992be0dacfbf",
   "metadata": {},
   "source": [
    "**Passo 8** - Compilamos o modelo (definimos um conjunto de parâmetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "02a6b6a2-cbd3-494a-a94b-24d18dc0ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae']) # optimizer define o Learning Rate. o 'adam' é mto usado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ae8d3-0b11-48ab-b4bf-cc1b1d0671f4",
   "metadata": {},
   "source": [
    "**Passo 9** - Treinamos o modelo mas garantimos que guardamos o MELHOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95dfe189-b2b2-4a35-b4b2-bc84036ef130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2163397.2500 - mae: 1356.4392 - val_loss: 2966602.5000 - val_mae: 1621.0436\n",
      "Epoch 2/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2156581.0000 - mae: 1353.9637 - val_loss: 2951692.7500 - val_mae: 1616.5496\n",
      "Epoch 3/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2132081.7500 - mae: 1345.3004 - val_loss: 2900854.7500 - val_mae: 1601.1882\n",
      "Epoch 4/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2055586.6250 - mae: 1317.9371 - val_loss: 2755206.5000 - val_mae: 1556.4321\n",
      "Epoch 5/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1867812.2500 - mae: 1247.0585 - val_loss: 2430373.0000 - val_mae: 1451.6796\n",
      "Epoch 6/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1495964.8750 - mae: 1098.2845 - val_loss: 1861068.0000 - val_mae: 1247.4792\n",
      "Epoch 7/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 983460.8750 - mae: 834.8069 - val_loss: 1131693.5000 - val_mae: 922.9866\n",
      "Epoch 8/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489620.7188 - mae: 503.5714 - val_loss: 557233.6875 - val_mae: 577.7868\n",
      "Epoch 9/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 261855.2500 - mae: 348.0551 - val_loss: 338716.1250 - val_mae: 445.8733\n",
      "Epoch 10/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 226581.0469 - mae: 344.3942 - val_loss: 293627.1250 - val_mae: 417.0883\n",
      "Epoch 11/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 226636.1094 - mae: 344.5194 - val_loss: 312997.4375 - val_mae: 428.3892\n",
      "Epoch 12/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 223530.4688 - mae: 349.3213 - val_loss: 281899.9688 - val_mae: 408.1143\n",
      "Epoch 13/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 222493.2344 - mae: 344.7150 - val_loss: 303326.1250 - val_mae: 421.1112\n",
      "Epoch 14/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 219626.6875 - mae: 342.6029 - val_loss: 288480.4062 - val_mae: 410.7809\n",
      "Epoch 15/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 219559.1406 - mae: 339.9350 - val_loss: 297718.1875 - val_mae: 416.3811\n",
      "Epoch 16/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 218111.2812 - mae: 345.3597 - val_loss: 283998.3750 - val_mae: 406.9938\n",
      "Epoch 17/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 217110.1875 - mae: 348.1991 - val_loss: 282167.7500 - val_mae: 404.9212\n",
      "Epoch 18/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 216479.6875 - mae: 337.2909 - val_loss: 300610.5625 - val_mae: 416.4323\n",
      "Epoch 19/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 217282.2344 - mae: 348.5472 - val_loss: 276919.0625 - val_mae: 400.2566\n",
      "Epoch 20/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 212928.0625 - mae: 336.9307 - val_loss: 289905.8750 - val_mae: 408.6672\n",
      "Epoch 21/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 214043.9062 - mae: 340.5341 - val_loss: 275482.8750 - val_mae: 398.3333\n",
      "Epoch 22/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 211882.8281 - mae: 339.7578 - val_loss: 287845.5000 - val_mae: 406.0749\n",
      "Epoch 23/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 210554.4062 - mae: 335.1895 - val_loss: 272863.1250 - val_mae: 395.3691\n",
      "Epoch 24/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 210499.1875 - mae: 340.1568 - val_loss: 280080.9375 - val_mae: 399.8276\n",
      "Epoch 25/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 208929.7812 - mae: 337.9537 - val_loss: 269054.0938 - val_mae: 391.6890\n",
      "Epoch 26/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 210162.4844 - mae: 332.6306 - val_loss: 281776.4062 - val_mae: 399.9986\n",
      "Epoch 27/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 207578.2344 - mae: 337.9216 - val_loss: 260213.1719 - val_mae: 385.1006\n",
      "Epoch 28/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 206782.2500 - mae: 338.3390 - val_loss: 264339.8125 - val_mae: 387.3745\n",
      "Epoch 29/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 206558.7656 - mae: 333.4162 - val_loss: 267573.0938 - val_mae: 389.1384\n",
      "Epoch 30/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 205288.6094 - mae: 336.9277 - val_loss: 264155.6250 - val_mae: 386.5449\n",
      "Epoch 31/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 204950.4219 - mae: 330.0021 - val_loss: 269460.7500 - val_mae: 390.1462\n",
      "Epoch 32/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 205404.5156 - mae: 337.9032 - val_loss: 255408.0000 - val_mae: 380.3472\n",
      "Epoch 33/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 203492.5312 - mae: 332.6957 - val_loss: 267577.7812 - val_mae: 389.1853\n",
      "Epoch 34/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 201930.4062 - mae: 329.1443 - val_loss: 256318.1094 - val_mae: 381.2560\n",
      "Epoch 35/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201575.6094 - mae: 333.2654 - val_loss: 254550.3906 - val_mae: 380.1827\n",
      "Epoch 36/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201997.0469 - mae: 337.2523 - val_loss: 254134.1094 - val_mae: 379.9797\n",
      "Epoch 37/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 199855.6875 - mae: 329.6693 - val_loss: 260670.4375 - val_mae: 384.7294\n",
      "Epoch 38/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201019.7812 - mae: 330.8988 - val_loss: 259523.7500 - val_mae: 384.1022\n",
      "Epoch 39/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 199049.7812 - mae: 326.5135 - val_loss: 263798.5312 - val_mae: 387.0765\n",
      "Epoch 40/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 201948.6250 - mae: 333.5177 - val_loss: 255601.6719 - val_mae: 381.4328\n",
      "Epoch 41/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198818.8750 - mae: 321.8274 - val_loss: 261711.7812 - val_mae: 385.6484\n",
      "Epoch 42/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 198705.1250 - mae: 328.6047 - val_loss: 247860.5312 - val_mae: 376.0406\n",
      "Epoch 43/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 196602.3125 - mae: 326.3831 - val_loss: 249928.0781 - val_mae: 377.6123\n",
      "Epoch 44/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 200647.8125 - mae: 336.5643 - val_loss: 249010.9688 - val_mae: 377.0343\n",
      "Epoch 45/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 195432.5000 - mae: 324.6565 - val_loss: 253434.3906 - val_mae: 380.2736\n",
      "Epoch 46/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 195807.6406 - mae: 319.9142 - val_loss: 254174.0781 - val_mae: 380.8102\n",
      "Epoch 47/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 196810.5312 - mae: 329.4798 - val_loss: 242763.0000 - val_mae: 372.5809\n",
      "Epoch 48/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 194475.1875 - mae: 319.7330 - val_loss: 248756.6406 - val_mae: 377.0074\n",
      "Epoch 49/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 193942.4219 - mae: 323.8951 - val_loss: 232886.1406 - val_mae: 365.2162\n",
      "Epoch 50/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 193988.3750 - mae: 331.3496 - val_loss: 242478.6719 - val_mae: 372.6112\n",
      "Epoch 51/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194230.2656 - mae: 315.0408 - val_loss: 247050.9688 - val_mae: 375.9733\n",
      "Epoch 52/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 193430.6250 - mae: 323.5702 - val_loss: 237905.7500 - val_mae: 369.3082\n",
      "Epoch 53/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 191403.8438 - mae: 319.9005 - val_loss: 240330.5625 - val_mae: 371.0016\n",
      "Epoch 54/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 191995.6875 - mae: 316.0681 - val_loss: 236073.3281 - val_mae: 367.9737\n",
      "Epoch 55/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190555.2031 - mae: 325.4246 - val_loss: 229207.6875 - val_mae: 362.6978\n",
      "Epoch 56/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190509.9375 - mae: 317.3080 - val_loss: 243042.2188 - val_mae: 373.1659\n",
      "Epoch 57/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 188593.5312 - mae: 317.7707 - val_loss: 229067.8125 - val_mae: 362.7553\n",
      "Epoch 58/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190927.5781 - mae: 326.5691 - val_loss: 233080.1094 - val_mae: 365.7711\n",
      "Epoch 59/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 192187.9688 - mae: 310.2307 - val_loss: 255638.3125 - val_mae: 381.5562\n",
      "Epoch 60/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 187728.8750 - mae: 316.3778 - val_loss: 219485.3125 - val_mae: 356.4871\n",
      "Epoch 61/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 187407.1875 - mae: 319.9352 - val_loss: 227706.1875 - val_mae: 361.8301\n",
      "Epoch 62/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 186511.6094 - mae: 316.3470 - val_loss: 231889.1562 - val_mae: 364.7394\n",
      "Epoch 63/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187036.3125 - mae: 312.9622 - val_loss: 236479.6875 - val_mae: 368.2044\n",
      "Epoch 64/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 186691.9375 - mae: 313.1190 - val_loss: 218323.5469 - val_mae: 355.7140\n",
      "Epoch 65/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185548.1875 - mae: 317.2209 - val_loss: 220464.0312 - val_mae: 357.0435\n",
      "Epoch 66/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 184733.9219 - mae: 314.3613 - val_loss: 231071.2500 - val_mae: 364.0769\n",
      "Epoch 67/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 184975.9844 - mae: 313.6581 - val_loss: 220377.4844 - val_mae: 357.0150\n",
      "Epoch 68/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 184451.1094 - mae: 314.9368 - val_loss: 224153.2188 - val_mae: 359.3813\n",
      "Epoch 69/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 183715.2812 - mae: 308.3311 - val_loss: 224770.9219 - val_mae: 359.6711\n",
      "Epoch 70/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 183802.6875 - mae: 306.3146 - val_loss: 225421.9375 - val_mae: 360.0589\n",
      "Epoch 71/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 182413.7031 - mae: 309.4256 - val_loss: 217805.0156 - val_mae: 355.0692\n",
      "Epoch 72/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 182818.8281 - mae: 310.1039 - val_loss: 216363.7344 - val_mae: 354.2211\n",
      "Epoch 73/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 182820.3438 - mae: 313.5568 - val_loss: 218567.0625 - val_mae: 355.4508\n",
      "Epoch 74/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 182548.2656 - mae: 307.1094 - val_loss: 216637.1719 - val_mae: 354.2315\n",
      "Epoch 75/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 181758.5000 - mae: 309.7314 - val_loss: 213303.0156 - val_mae: 351.7210\n",
      "Epoch 76/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 181324.0000 - mae: 306.9863 - val_loss: 216776.2656 - val_mae: 354.2120\n",
      "Epoch 77/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180650.1406 - mae: 305.8887 - val_loss: 217914.2656 - val_mae: 354.9044\n",
      "Epoch 78/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 181787.2812 - mae: 308.6062 - val_loss: 221016.4375 - val_mae: 356.8808\n",
      "Epoch 79/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180515.4219 - mae: 303.3211 - val_loss: 215713.0625 - val_mae: 353.3120\n",
      "Epoch 80/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 180359.3125 - mae: 309.7905 - val_loss: 206734.4375 - val_mae: 347.0242\n",
      "Epoch 81/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 179956.5156 - mae: 305.3322 - val_loss: 222914.5469 - val_mae: 357.5046\n",
      "Epoch 82/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 178975.1875 - mae: 304.6158 - val_loss: 211579.5781 - val_mae: 350.3439\n",
      "Epoch 83/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 179149.0781 - mae: 304.3900 - val_loss: 215915.0625 - val_mae: 353.0045\n",
      "Epoch 84/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 179138.2500 - mae: 305.8870 - val_loss: 210949.5938 - val_mae: 349.7460\n",
      "Epoch 85/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 178600.9062 - mae: 304.1853 - val_loss: 213423.0625 - val_mae: 351.2524\n",
      "Epoch 86/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 179558.2812 - mae: 308.5876 - val_loss: 212669.1562 - val_mae: 350.8396\n",
      "Epoch 87/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 178099.6875 - mae: 296.2990 - val_loss: 222310.3281 - val_mae: 356.9355\n",
      "Epoch 88/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 176228.7344 - mae: 299.4778 - val_loss: 201608.6875 - val_mae: 342.9218\n",
      "Epoch 89/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 177291.8906 - mae: 304.3703 - val_loss: 204447.0156 - val_mae: 344.8839\n",
      "Epoch 90/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177771.8438 - mae: 299.3468 - val_loss: 207803.5781 - val_mae: 347.0362\n",
      "Epoch 91/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177462.8438 - mae: 302.3568 - val_loss: 211105.1875 - val_mae: 349.2730\n",
      "Epoch 92/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 176905.8750 - mae: 305.6230 - val_loss: 198437.6875 - val_mae: 340.4796\n",
      "Epoch 93/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 178697.4375 - mae: 298.7590 - val_loss: 211278.7812 - val_mae: 349.2074\n",
      "Epoch 94/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 177673.8438 - mae: 308.0430 - val_loss: 195802.3594 - val_mae: 338.1506\n",
      "Epoch 95/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 176635.1406 - mae: 297.5561 - val_loss: 208823.2031 - val_mae: 347.3871\n",
      "Epoch 96/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 175846.3125 - mae: 302.0659 - val_loss: 201308.7812 - val_mae: 342.1086\n",
      "Epoch 97/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 175269.8438 - mae: 295.9835 - val_loss: 207864.9844 - val_mae: 346.7067\n",
      "Epoch 98/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174292.7031 - mae: 299.3601 - val_loss: 200157.9062 - val_mae: 341.1450\n",
      "Epoch 99/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 174115.5156 - mae: 299.9193 - val_loss: 203956.7344 - val_mae: 343.8278\n",
      "Epoch 100/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 174024.1875 - mae: 295.9272 - val_loss: 207835.8906 - val_mae: 346.3493\n",
      "Epoch 101/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174025.7500 - mae: 298.0708 - val_loss: 196237.5938 - val_mae: 338.2231\n",
      "Epoch 102/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 175640.9375 - mae: 304.5277 - val_loss: 207466.7812 - val_mae: 345.8935\n",
      "Epoch 103/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 174058.9375 - mae: 294.5335 - val_loss: 206172.0625 - val_mae: 344.7281\n",
      "Epoch 104/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 173926.6875 - mae: 300.9271 - val_loss: 193731.1406 - val_mae: 335.8006\n",
      "Epoch 105/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 177112.2344 - mae: 293.4659 - val_loss: 208161.4062 - val_mae: 346.1486\n",
      "Epoch 106/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 173379.9688 - mae: 298.7232 - val_loss: 194031.0625 - val_mae: 336.0938\n",
      "Epoch 107/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 172812.4062 - mae: 297.9717 - val_loss: 206315.2500 - val_mae: 344.5076\n",
      "Epoch 108/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173420.9531 - mae: 296.8688 - val_loss: 204267.7969 - val_mae: 343.0883\n",
      "Epoch 109/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172220.5625 - mae: 292.6376 - val_loss: 200891.7500 - val_mae: 340.5872\n",
      "Epoch 110/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 173214.0625 - mae: 297.5247 - val_loss: 195451.8750 - val_mae: 336.7055\n",
      "Epoch 111/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 171484.0781 - mae: 293.7384 - val_loss: 202277.1875 - val_mae: 341.4372\n",
      "Epoch 112/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173032.9688 - mae: 290.6106 - val_loss: 198656.2344 - val_mae: 338.7879\n",
      "Epoch 113/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171430.9844 - mae: 294.7125 - val_loss: 195631.2344 - val_mae: 336.7982\n",
      "Epoch 114/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171625.0938 - mae: 296.4187 - val_loss: 195408.0000 - val_mae: 336.3104\n",
      "Epoch 115/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173748.7812 - mae: 291.8712 - val_loss: 201945.5781 - val_mae: 340.7391\n",
      "Epoch 116/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 171152.8750 - mae: 294.1121 - val_loss: 189871.2031 - val_mae: 332.0880\n",
      "Epoch 117/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171381.7969 - mae: 296.9738 - val_loss: 191779.0469 - val_mae: 333.5013\n",
      "Epoch 118/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173309.0625 - mae: 290.5089 - val_loss: 203087.0156 - val_mae: 341.5787\n",
      "Epoch 119/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173631.6094 - mae: 298.9917 - val_loss: 191369.6406 - val_mae: 332.8789\n",
      "Epoch 120/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170942.8594 - mae: 292.5923 - val_loss: 199415.5781 - val_mae: 339.0619\n",
      "Epoch 121/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171627.9375 - mae: 289.8917 - val_loss: 199307.3281 - val_mae: 339.1028\n",
      "Epoch 122/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 171032.2188 - mae: 296.2502 - val_loss: 185457.6875 - val_mae: 328.1992\n",
      "Epoch 123/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170405.7969 - mae: 294.5444 - val_loss: 193735.9375 - val_mae: 334.3170\n",
      "Epoch 124/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170722.9375 - mae: 290.9888 - val_loss: 196652.4062 - val_mae: 336.8645\n",
      "Epoch 125/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171065.7656 - mae: 289.2163 - val_loss: 198081.9062 - val_mae: 338.1173\n",
      "Epoch 126/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 170150.6719 - mae: 291.0956 - val_loss: 190917.3906 - val_mae: 332.2415\n",
      "Epoch 127/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170612.8125 - mae: 293.9059 - val_loss: 196414.0469 - val_mae: 336.9578\n",
      "Epoch 128/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 173304.6875 - mae: 298.2365 - val_loss: 187273.7500 - val_mae: 329.1689\n",
      "Epoch 129/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173387.7188 - mae: 289.8168 - val_loss: 201652.1875 - val_mae: 340.8739\n",
      "Epoch 130/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 170665.2188 - mae: 293.3643 - val_loss: 194366.1875 - val_mae: 335.0753\n",
      "Epoch 131/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169491.5938 - mae: 292.4377 - val_loss: 191052.1406 - val_mae: 332.4456\n",
      "Epoch 132/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 170389.3438 - mae: 291.3811 - val_loss: 200684.3125 - val_mae: 340.2014\n",
      "Epoch 133/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 169145.7969 - mae: 289.8427 - val_loss: 185832.6250 - val_mae: 327.9049\n",
      "Epoch 134/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 169278.5781 - mae: 291.6261 - val_loss: 189534.4844 - val_mae: 331.3130\n",
      "Epoch 135/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170260.5938 - mae: 288.8894 - val_loss: 196977.2969 - val_mae: 337.6925\n",
      "Epoch 136/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 170616.7969 - mae: 292.3510 - val_loss: 188183.9219 - val_mae: 330.1816\n",
      "Epoch 137/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 169012.0469 - mae: 291.3756 - val_loss: 189075.1250 - val_mae: 330.9495\n",
      "Epoch 138/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 170510.5938 - mae: 294.3306 - val_loss: 192541.5312 - val_mae: 334.0870\n",
      "Epoch 139/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168716.4375 - mae: 287.9770 - val_loss: 195898.4531 - val_mae: 336.7681\n",
      "Epoch 140/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169095.6406 - mae: 290.9698 - val_loss: 193223.7031 - val_mae: 334.6216\n",
      "Epoch 141/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 168679.8125 - mae: 291.6807 - val_loss: 190213.2188 - val_mae: 332.2124\n",
      "Epoch 142/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169697.4219 - mae: 287.0747 - val_loss: 199230.5000 - val_mae: 339.6452\n",
      "Epoch 143/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169539.7969 - mae: 292.6879 - val_loss: 186772.1406 - val_mae: 329.3389\n",
      "Epoch 144/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168787.7500 - mae: 288.9584 - val_loss: 193758.0625 - val_mae: 335.1850\n",
      "Epoch 145/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 169951.3281 - mae: 294.4182 - val_loss: 185785.5781 - val_mae: 328.7332\n",
      "Epoch 146/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 167229.5781 - mae: 289.0514 - val_loss: 195792.1562 - val_mae: 337.0859\n",
      "Epoch 147/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171147.7188 - mae: 286.2743 - val_loss: 199757.0781 - val_mae: 340.0667\n",
      "Epoch 148/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169873.7188 - mae: 293.2583 - val_loss: 175274.2812 - val_mae: 318.2705\n",
      "Epoch 149/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 171387.7969 - mae: 290.6796 - val_loss: 200763.5156 - val_mae: 340.8271\n",
      "Epoch 150/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 168355.6562 - mae: 291.5078 - val_loss: 180250.4062 - val_mae: 323.6291\n",
      "Epoch 151/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168227.4375 - mae: 290.7546 - val_loss: 193799.9062 - val_mae: 335.3473\n",
      "Epoch 152/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 167385.0312 - mae: 288.0862 - val_loss: 191625.7500 - val_mae: 333.5961\n",
      "Epoch 153/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167108.0000 - mae: 287.8118 - val_loss: 188772.6875 - val_mae: 331.4235\n",
      "Epoch 154/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169016.3906 - mae: 289.2097 - val_loss: 195725.9375 - val_mae: 336.9231\n",
      "Epoch 155/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170768.2812 - mae: 295.3718 - val_loss: 183357.9375 - val_mae: 326.4355\n",
      "Epoch 156/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166943.2500 - mae: 287.9310 - val_loss: 192279.7656 - val_mae: 334.3054\n",
      "Epoch 157/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168130.2656 - mae: 289.6360 - val_loss: 196526.5000 - val_mae: 337.6402\n",
      "Epoch 158/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167153.6406 - mae: 286.9196 - val_loss: 184705.9062 - val_mae: 327.8199\n",
      "Epoch 159/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 167575.5938 - mae: 289.0910 - val_loss: 189346.5938 - val_mae: 331.8258\n",
      "Epoch 160/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166551.3281 - mae: 289.3445 - val_loss: 185678.1094 - val_mae: 328.4877\n",
      "Epoch 161/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168481.5000 - mae: 289.4905 - val_loss: 182483.5312 - val_mae: 326.0093\n",
      "Epoch 162/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 167857.6562 - mae: 286.7474 - val_loss: 186438.3438 - val_mae: 329.5123\n",
      "Epoch 163/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167371.6406 - mae: 290.4721 - val_loss: 182455.5312 - val_mae: 325.6848\n",
      "Epoch 164/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167231.2812 - mae: 287.7159 - val_loss: 188162.7812 - val_mae: 330.7542\n",
      "Epoch 165/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168095.3594 - mae: 291.2263 - val_loss: 186432.5000 - val_mae: 329.1894\n",
      "Epoch 166/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 168774.3906 - mae: 288.5832 - val_loss: 190007.1719 - val_mae: 332.2908\n",
      "Epoch 167/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166642.3906 - mae: 289.2261 - val_loss: 188715.0938 - val_mae: 331.2456\n",
      "Epoch 168/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166799.8281 - mae: 287.0321 - val_loss: 192893.4844 - val_mae: 334.6755\n",
      "Epoch 169/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 167230.7500 - mae: 291.9440 - val_loss: 181256.7656 - val_mae: 324.4734\n",
      "Epoch 170/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165665.0469 - mae: 288.5663 - val_loss: 190119.5625 - val_mae: 332.5577\n",
      "Epoch 171/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166594.5625 - mae: 288.1406 - val_loss: 187461.0625 - val_mae: 330.2028\n",
      "Epoch 172/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166429.0625 - mae: 286.2477 - val_loss: 190483.9688 - val_mae: 332.6417\n",
      "Epoch 173/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167375.9375 - mae: 284.7376 - val_loss: 183181.0312 - val_mae: 326.4324\n",
      "Epoch 174/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 165880.5625 - mae: 289.2220 - val_loss: 183188.3438 - val_mae: 326.6365\n",
      "Epoch 175/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166576.6406 - mae: 289.3739 - val_loss: 189847.2656 - val_mae: 332.0993\n",
      "Epoch 176/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167020.9062 - mae: 286.5961 - val_loss: 186108.0938 - val_mae: 328.9482\n",
      "Epoch 177/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165644.5156 - mae: 288.5060 - val_loss: 181648.6094 - val_mae: 324.8018\n",
      "Epoch 178/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166748.0938 - mae: 292.0311 - val_loss: 177780.9688 - val_mae: 321.1263\n",
      "Epoch 179/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165899.1562 - mae: 287.1066 - val_loss: 191148.2656 - val_mae: 333.2372\n",
      "Epoch 180/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 167004.8125 - mae: 288.9705 - val_loss: 186140.6094 - val_mae: 329.2213\n",
      "Epoch 181/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 168578.2656 - mae: 285.6556 - val_loss: 191787.9219 - val_mae: 333.6114\n",
      "Epoch 182/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166064.8438 - mae: 289.3114 - val_loss: 177943.7344 - val_mae: 321.5930\n",
      "Epoch 183/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 168484.7031 - mae: 294.6419 - val_loss: 181518.2031 - val_mae: 324.8344\n",
      "Epoch 184/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165387.5156 - mae: 284.1832 - val_loss: 194861.8125 - val_mae: 336.1042\n",
      "Epoch 185/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166524.7031 - mae: 288.2926 - val_loss: 188681.6094 - val_mae: 331.1394\n",
      "Epoch 186/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 165642.4688 - mae: 288.1987 - val_loss: 184542.3906 - val_mae: 327.5863\n",
      "Epoch 187/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166671.8750 - mae: 287.7656 - val_loss: 186702.3125 - val_mae: 329.5190\n",
      "Epoch 188/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167365.2031 - mae: 291.9607 - val_loss: 181425.5312 - val_mae: 324.8392\n",
      "Epoch 189/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164858.3906 - mae: 284.7295 - val_loss: 192634.5625 - val_mae: 334.4617\n",
      "Epoch 190/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166266.8906 - mae: 286.7855 - val_loss: 179929.1094 - val_mae: 323.6801\n",
      "Epoch 191/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 164927.6406 - mae: 288.8515 - val_loss: 184319.0156 - val_mae: 327.4275\n",
      "Epoch 192/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164515.2656 - mae: 286.7173 - val_loss: 189467.2344 - val_mae: 331.8987\n",
      "Epoch 193/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164961.2031 - mae: 285.7048 - val_loss: 191062.8125 - val_mae: 332.9822\n",
      "Epoch 194/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166426.5625 - mae: 290.0424 - val_loss: 180546.6406 - val_mae: 324.3011\n",
      "Epoch 195/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168270.5625 - mae: 287.3990 - val_loss: 181327.8438 - val_mae: 324.6559\n",
      "Epoch 196/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166665.1094 - mae: 286.4481 - val_loss: 184534.3750 - val_mae: 327.4451\n",
      "Epoch 197/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 165702.8125 - mae: 287.7756 - val_loss: 181571.0000 - val_mae: 325.2007\n",
      "Epoch 198/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 164704.8750 - mae: 290.6933 - val_loss: 182506.1250 - val_mae: 326.0183\n",
      "Epoch 199/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164547.3906 - mae: 288.1617 - val_loss: 186177.0312 - val_mae: 329.0847\n",
      "Epoch 200/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165309.5156 - mae: 285.2820 - val_loss: 191022.4688 - val_mae: 332.9447\n",
      "Epoch 201/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165103.1406 - mae: 288.0926 - val_loss: 187672.1406 - val_mae: 330.1871\n",
      "Epoch 202/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164153.1406 - mae: 287.3424 - val_loss: 187007.1250 - val_mae: 329.7105\n",
      "Epoch 203/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 164985.7969 - mae: 282.8121 - val_loss: 193343.6875 - val_mae: 334.8179\n",
      "Epoch 204/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164302.3281 - mae: 284.7683 - val_loss: 174591.1875 - val_mae: 320.3695\n",
      "Epoch 205/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 164463.9219 - mae: 290.4243 - val_loss: 184230.9375 - val_mae: 327.6404\n",
      "Epoch 206/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165039.5469 - mae: 285.8596 - val_loss: 183164.9688 - val_mae: 326.8535\n",
      "Epoch 207/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165337.3906 - mae: 287.5382 - val_loss: 191012.0625 - val_mae: 333.1589\n",
      "Epoch 208/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163385.8906 - mae: 286.4700 - val_loss: 178888.1250 - val_mae: 323.8425\n",
      "Epoch 209/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165242.4062 - mae: 287.3654 - val_loss: 188384.9688 - val_mae: 330.7753\n",
      "Epoch 210/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164645.2656 - mae: 289.5089 - val_loss: 182255.5625 - val_mae: 326.4283\n",
      "Epoch 211/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164439.6094 - mae: 289.3562 - val_loss: 177741.6875 - val_mae: 323.1118\n",
      "Epoch 212/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163386.6406 - mae: 285.8960 - val_loss: 192998.3281 - val_mae: 334.4919\n",
      "Epoch 213/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 164372.1875 - mae: 287.0793 - val_loss: 181491.6250 - val_mae: 326.1523\n",
      "Epoch 214/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163501.2969 - mae: 284.8401 - val_loss: 188935.5469 - val_mae: 331.1456\n",
      "Epoch 215/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163895.5938 - mae: 286.4088 - val_loss: 185184.1406 - val_mae: 328.8368\n",
      "Epoch 216/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164410.2188 - mae: 288.7122 - val_loss: 182818.9531 - val_mae: 326.8784\n",
      "Epoch 217/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163171.7188 - mae: 284.4957 - val_loss: 191437.5000 - val_mae: 333.4240\n",
      "Epoch 218/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163509.8125 - mae: 283.2211 - val_loss: 189790.4531 - val_mae: 331.9685\n",
      "Epoch 219/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 165809.8125 - mae: 291.6496 - val_loss: 183547.2344 - val_mae: 327.4457\n",
      "Epoch 220/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163936.6094 - mae: 284.8302 - val_loss: 190925.7656 - val_mae: 333.0403\n",
      "Epoch 221/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163707.6250 - mae: 283.6336 - val_loss: 179355.5781 - val_mae: 324.6678\n",
      "Epoch 222/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164515.0625 - mae: 288.3435 - val_loss: 189913.5312 - val_mae: 331.8578\n",
      "Epoch 223/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163703.5000 - mae: 285.5485 - val_loss: 182829.4219 - val_mae: 327.3223\n",
      "Epoch 224/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163611.9375 - mae: 284.9135 - val_loss: 191055.3594 - val_mae: 332.9661\n",
      "Epoch 225/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 165235.0156 - mae: 289.6490 - val_loss: 181563.4844 - val_mae: 326.5759\n",
      "Epoch 226/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 165487.3750 - mae: 285.2120 - val_loss: 190161.8125 - val_mae: 332.4627\n",
      "Epoch 227/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163518.6875 - mae: 286.1492 - val_loss: 183167.6094 - val_mae: 327.6740\n",
      "Epoch 228/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 162432.7500 - mae: 286.7364 - val_loss: 174961.1875 - val_mae: 321.7804\n",
      "Epoch 229/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162985.3281 - mae: 287.8099 - val_loss: 183708.2656 - val_mae: 328.3253\n",
      "Epoch 230/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163405.1406 - mae: 287.9861 - val_loss: 184582.1094 - val_mae: 328.7494\n",
      "Epoch 231/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162524.2344 - mae: 283.6054 - val_loss: 191513.7188 - val_mae: 333.3540\n",
      "Epoch 232/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162525.4531 - mae: 284.1688 - val_loss: 183321.3125 - val_mae: 327.9921\n",
      "Epoch 233/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165222.7500 - mae: 291.8993 - val_loss: 174479.1875 - val_mae: 321.4718\n",
      "Epoch 234/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166996.9844 - mae: 282.3915 - val_loss: 188222.0156 - val_mae: 331.1979\n",
      "Epoch 235/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163339.5312 - mae: 286.4735 - val_loss: 182387.5312 - val_mae: 327.6363\n",
      "Epoch 236/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162547.1094 - mae: 284.3961 - val_loss: 184220.0938 - val_mae: 328.9910\n",
      "Epoch 237/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 162643.6875 - mae: 284.7727 - val_loss: 189093.7188 - val_mae: 331.7085\n",
      "Epoch 238/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162883.0000 - mae: 285.4079 - val_loss: 180227.3906 - val_mae: 325.8301\n",
      "Epoch 239/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162631.8281 - mae: 287.4222 - val_loss: 182634.5156 - val_mae: 327.6163\n",
      "Epoch 240/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 162822.8594 - mae: 283.9683 - val_loss: 191709.5469 - val_mae: 333.8907\n",
      "Epoch 241/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 162182.4531 - mae: 283.3760 - val_loss: 177411.3125 - val_mae: 323.8958\n",
      "Epoch 242/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162749.6250 - mae: 287.3359 - val_loss: 180011.3906 - val_mae: 325.8761\n",
      "Epoch 243/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161898.7188 - mae: 285.2996 - val_loss: 183895.3125 - val_mae: 328.6527\n",
      "Epoch 244/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162944.6406 - mae: 282.6931 - val_loss: 184673.5000 - val_mae: 329.1489\n",
      "Epoch 245/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163642.1562 - mae: 290.5412 - val_loss: 178401.2188 - val_mae: 324.6375\n",
      "Epoch 246/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161783.3906 - mae: 283.6839 - val_loss: 184915.1094 - val_mae: 329.1505\n",
      "Epoch 247/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161815.0625 - mae: 282.4790 - val_loss: 185060.4531 - val_mae: 329.2846\n",
      "Epoch 248/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163682.8125 - mae: 290.4565 - val_loss: 178122.8281 - val_mae: 324.7385\n",
      "Epoch 249/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165407.8750 - mae: 283.2643 - val_loss: 183067.4219 - val_mae: 328.3583\n",
      "Epoch 250/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162840.2500 - mae: 287.5535 - val_loss: 180917.5625 - val_mae: 326.2531\n",
      "Epoch 251/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162375.8281 - mae: 286.0900 - val_loss: 187145.6250 - val_mae: 331.0427\n",
      "Epoch 252/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 162187.5000 - mae: 281.2157 - val_loss: 192209.9375 - val_mae: 333.8824\n",
      "Epoch 253/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160810.9375 - mae: 281.0570 - val_loss: 182369.2812 - val_mae: 327.6834\n",
      "Epoch 254/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160956.2188 - mae: 284.2806 - val_loss: 178378.7656 - val_mae: 324.8683\n",
      "Epoch 255/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161875.0938 - mae: 285.8966 - val_loss: 174472.0781 - val_mae: 322.1820\n",
      "Epoch 256/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161449.7031 - mae: 287.6547 - val_loss: 175007.4531 - val_mae: 322.7268\n",
      "Epoch 257/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162415.0469 - mae: 284.2791 - val_loss: 192263.6094 - val_mae: 334.3934\n",
      "Epoch 258/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161267.5938 - mae: 281.2065 - val_loss: 182392.2344 - val_mae: 328.1108\n",
      "Epoch 259/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162631.7031 - mae: 288.7858 - val_loss: 180507.1094 - val_mae: 326.7204\n",
      "Epoch 260/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163537.7500 - mae: 283.5601 - val_loss: 190123.0000 - val_mae: 333.2778\n",
      "Epoch 261/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161974.4688 - mae: 286.5627 - val_loss: 173598.6875 - val_mae: 321.5959\n",
      "Epoch 262/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162727.0625 - mae: 288.0582 - val_loss: 179217.6719 - val_mae: 325.6054\n",
      "Epoch 263/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163643.1875 - mae: 280.1716 - val_loss: 185573.5625 - val_mae: 330.2835\n",
      "Epoch 264/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161431.2500 - mae: 287.1031 - val_loss: 178684.2969 - val_mae: 325.4301\n",
      "Epoch 265/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161424.8594 - mae: 286.0519 - val_loss: 185123.0781 - val_mae: 329.9917\n",
      "Epoch 266/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161530.3125 - mae: 283.3686 - val_loss: 185831.0938 - val_mae: 330.2728\n",
      "Epoch 267/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162268.7031 - mae: 287.0742 - val_loss: 182415.1875 - val_mae: 328.0610\n",
      "Epoch 268/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 162648.5938 - mae: 281.1236 - val_loss: 190845.9844 - val_mae: 333.6216\n",
      "Epoch 269/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161049.3438 - mae: 286.3535 - val_loss: 174614.2031 - val_mae: 322.4157\n",
      "Epoch 270/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160940.0625 - mae: 287.8857 - val_loss: 184138.2031 - val_mae: 329.5047\n",
      "Epoch 271/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160788.5000 - mae: 281.0718 - val_loss: 184792.9375 - val_mae: 329.7127\n",
      "Epoch 272/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160425.0781 - mae: 281.6989 - val_loss: 182054.0938 - val_mae: 328.1025\n",
      "Epoch 273/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160994.4062 - mae: 283.4271 - val_loss: 175333.6875 - val_mae: 322.7967\n",
      "Epoch 274/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160568.0781 - mae: 283.5104 - val_loss: 181708.1719 - val_mae: 327.5637\n",
      "Epoch 275/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161207.6719 - mae: 285.6258 - val_loss: 180963.7656 - val_mae: 327.4430\n",
      "Epoch 276/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160718.7969 - mae: 282.8431 - val_loss: 182935.2969 - val_mae: 328.7834\n",
      "Epoch 277/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160301.3594 - mae: 280.5834 - val_loss: 186674.4219 - val_mae: 331.0744\n",
      "Epoch 278/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160902.6250 - mae: 285.5083 - val_loss: 175331.1562 - val_mae: 323.0162\n",
      "Epoch 279/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159426.7812 - mae: 283.4803 - val_loss: 186787.5625 - val_mae: 331.5776\n",
      "Epoch 280/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160582.2969 - mae: 282.8296 - val_loss: 179187.5469 - val_mae: 325.9928\n",
      "Epoch 281/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 162077.1250 - mae: 278.8361 - val_loss: 191279.6719 - val_mae: 334.0509\n",
      "Epoch 282/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159358.0625 - mae: 282.4015 - val_loss: 177639.7812 - val_mae: 325.0548\n",
      "Epoch 283/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159988.6406 - mae: 283.1489 - val_loss: 177778.1875 - val_mae: 325.2911\n",
      "Epoch 284/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163339.3125 - mae: 291.2951 - val_loss: 180835.8125 - val_mae: 327.4735\n",
      "Epoch 285/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160271.4688 - mae: 281.5938 - val_loss: 185024.5625 - val_mae: 330.4044\n",
      "Epoch 286/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161373.5625 - mae: 283.0718 - val_loss: 191481.9531 - val_mae: 334.5472\n",
      "Epoch 287/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160442.5469 - mae: 280.4404 - val_loss: 174540.7344 - val_mae: 323.1009\n",
      "Epoch 288/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159927.7812 - mae: 283.6530 - val_loss: 182413.4219 - val_mae: 328.8410\n",
      "Epoch 289/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160110.4219 - mae: 281.7029 - val_loss: 179291.8906 - val_mae: 326.0572\n",
      "Epoch 290/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160042.0781 - mae: 285.1008 - val_loss: 172923.8750 - val_mae: 321.6701\n",
      "Epoch 291/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159321.3281 - mae: 283.3665 - val_loss: 185407.5000 - val_mae: 330.6504\n",
      "Epoch 292/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159711.2188 - mae: 283.3485 - val_loss: 180964.7500 - val_mae: 327.6310\n",
      "Epoch 293/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159530.6094 - mae: 284.6190 - val_loss: 181730.1562 - val_mae: 328.2471\n",
      "Epoch 294/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162263.5625 - mae: 277.6317 - val_loss: 190890.7500 - val_mae: 334.1103\n",
      "Epoch 295/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162171.8125 - mae: 288.2421 - val_loss: 175065.4219 - val_mae: 323.1388\n",
      "Epoch 296/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160964.4062 - mae: 281.2372 - val_loss: 182684.6406 - val_mae: 328.8709\n",
      "Epoch 297/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160119.5000 - mae: 282.5257 - val_loss: 176658.3750 - val_mae: 324.5287\n",
      "Epoch 298/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160342.7031 - mae: 280.7224 - val_loss: 179168.3438 - val_mae: 326.3087\n",
      "Epoch 299/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160681.5938 - mae: 286.9091 - val_loss: 176837.0781 - val_mae: 324.5892\n",
      "Epoch 300/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158560.0312 - mae: 282.8812 - val_loss: 185646.9688 - val_mae: 330.9517\n",
      "Epoch 301/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159931.4219 - mae: 283.1832 - val_loss: 185629.5781 - val_mae: 331.0821\n",
      "Epoch 302/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159577.1406 - mae: 281.3839 - val_loss: 182203.2188 - val_mae: 328.6985\n",
      "Epoch 303/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160467.2656 - mae: 279.1544 - val_loss: 187834.1250 - val_mae: 332.3694\n",
      "Epoch 304/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158325.0625 - mae: 282.7554 - val_loss: 175669.7188 - val_mae: 324.4989\n",
      "Epoch 305/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163375.4219 - mae: 284.1112 - val_loss: 193010.5938 - val_mae: 335.7977\n",
      "Epoch 306/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158701.8750 - mae: 284.0684 - val_loss: 175387.5000 - val_mae: 323.7664\n",
      "Epoch 307/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159745.1875 - mae: 286.7669 - val_loss: 184203.1719 - val_mae: 330.1013\n",
      "Epoch 308/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159262.9688 - mae: 278.8065 - val_loss: 181087.4375 - val_mae: 327.9142\n",
      "Epoch 309/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159094.1094 - mae: 284.4772 - val_loss: 175337.0469 - val_mae: 324.0550\n",
      "Epoch 310/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 158571.2656 - mae: 280.8187 - val_loss: 183409.9375 - val_mae: 329.8172\n",
      "Epoch 311/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159159.7188 - mae: 280.9940 - val_loss: 184997.0000 - val_mae: 330.5558\n",
      "Epoch 312/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158538.9062 - mae: 281.0678 - val_loss: 179994.3281 - val_mae: 327.3345\n",
      "Epoch 313/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158852.3750 - mae: 281.6139 - val_loss: 186053.4688 - val_mae: 331.6422\n",
      "Epoch 314/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158582.0938 - mae: 278.4456 - val_loss: 178686.1250 - val_mae: 326.2555\n",
      "Epoch 315/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161361.1562 - mae: 289.5386 - val_loss: 177821.2500 - val_mae: 325.9830\n",
      "Epoch 316/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159021.4531 - mae: 280.9071 - val_loss: 179951.3281 - val_mae: 327.1717\n",
      "Epoch 317/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158503.2031 - mae: 279.3245 - val_loss: 185600.5312 - val_mae: 331.2427\n",
      "Epoch 318/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157625.3906 - mae: 279.3048 - val_loss: 175498.4844 - val_mae: 323.8185\n",
      "Epoch 319/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158398.7656 - mae: 283.7001 - val_loss: 180006.0938 - val_mae: 327.4720\n",
      "Epoch 320/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158153.7656 - mae: 282.9088 - val_loss: 176407.4375 - val_mae: 324.6240\n",
      "Epoch 321/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159347.6719 - mae: 280.4099 - val_loss: 187161.6562 - val_mae: 332.0732\n",
      "Epoch 322/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157845.0156 - mae: 279.2159 - val_loss: 178822.5312 - val_mae: 326.5199\n",
      "Epoch 323/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160366.1562 - mae: 288.7719 - val_loss: 174113.9531 - val_mae: 322.8678\n",
      "Epoch 324/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160142.6719 - mae: 281.5453 - val_loss: 181659.2031 - val_mae: 328.5873\n",
      "Epoch 325/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159063.6875 - mae: 280.8947 - val_loss: 188998.8906 - val_mae: 333.2819\n",
      "Epoch 326/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158907.5781 - mae: 281.4323 - val_loss: 179083.3906 - val_mae: 326.9836\n",
      "Epoch 327/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157749.4531 - mae: 280.2212 - val_loss: 180381.1094 - val_mae: 328.0117\n",
      "Epoch 328/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159596.8438 - mae: 286.1061 - val_loss: 172377.7969 - val_mae: 321.6503\n",
      "Epoch 329/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159072.9219 - mae: 280.5467 - val_loss: 181753.2500 - val_mae: 328.7226\n",
      "Epoch 330/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158203.2031 - mae: 280.8199 - val_loss: 179659.7188 - val_mae: 327.4086\n",
      "Epoch 331/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157980.5938 - mae: 278.5354 - val_loss: 183072.7656 - val_mae: 329.3908\n",
      "Epoch 332/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157896.8281 - mae: 279.1085 - val_loss: 178676.3750 - val_mae: 326.8956\n",
      "Epoch 333/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157819.2500 - mae: 282.4026 - val_loss: 176513.3906 - val_mae: 325.1936\n",
      "Epoch 334/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159085.2656 - mae: 280.6544 - val_loss: 173773.4844 - val_mae: 322.8082\n",
      "Epoch 335/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158042.3125 - mae: 284.0860 - val_loss: 178023.8594 - val_mae: 326.1493\n",
      "Epoch 336/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157580.0156 - mae: 279.5295 - val_loss: 183073.4062 - val_mae: 329.7919\n",
      "Epoch 337/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157810.8281 - mae: 282.8185 - val_loss: 177154.4844 - val_mae: 325.4556\n",
      "Epoch 338/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159060.8906 - mae: 284.1495 - val_loss: 174777.5469 - val_mae: 323.8077\n",
      "Epoch 339/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157824.6875 - mae: 281.8040 - val_loss: 182229.5781 - val_mae: 328.8980\n",
      "Epoch 340/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159467.2031 - mae: 276.2851 - val_loss: 193054.3594 - val_mae: 335.8870\n",
      "Epoch 341/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159710.3594 - mae: 284.5659 - val_loss: 174848.2031 - val_mae: 323.5970\n",
      "Epoch 342/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157360.8281 - mae: 280.2662 - val_loss: 185154.1562 - val_mae: 330.8451\n",
      "Epoch 343/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157730.2812 - mae: 281.0422 - val_loss: 176207.5625 - val_mae: 324.7209\n",
      "Epoch 344/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157148.8594 - mae: 279.7942 - val_loss: 185167.9844 - val_mae: 330.9077\n",
      "Epoch 345/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158413.6875 - mae: 282.8550 - val_loss: 178546.7031 - val_mae: 326.5658\n",
      "Epoch 346/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160682.3125 - mae: 289.9355 - val_loss: 188177.6719 - val_mae: 333.5267\n",
      "Epoch 347/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157801.3750 - mae: 276.3710 - val_loss: 188769.8750 - val_mae: 333.4152\n",
      "Epoch 348/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157507.4688 - mae: 279.2804 - val_loss: 178963.6719 - val_mae: 326.8676\n",
      "Epoch 349/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157137.7188 - mae: 279.9385 - val_loss: 178954.5625 - val_mae: 326.8424\n",
      "Epoch 350/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156784.9375 - mae: 278.8877 - val_loss: 181337.8125 - val_mae: 328.4355\n",
      "Epoch 351/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160917.1719 - mae: 288.6105 - val_loss: 177576.7031 - val_mae: 325.8595\n",
      "Epoch 352/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157158.9219 - mae: 279.5797 - val_loss: 188903.3438 - val_mae: 333.4012\n",
      "Epoch 353/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157045.7188 - mae: 275.4162 - val_loss: 188472.0312 - val_mae: 333.5753\n",
      "Epoch 354/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158015.0781 - mae: 282.5432 - val_loss: 173926.8125 - val_mae: 323.2159\n",
      "Epoch 355/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159546.8438 - mae: 279.2218 - val_loss: 177278.7344 - val_mae: 325.9571\n",
      "Epoch 356/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156190.3594 - mae: 281.6791 - val_loss: 180432.6875 - val_mae: 328.0187\n",
      "Epoch 357/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158182.3594 - mae: 279.1845 - val_loss: 177266.4375 - val_mae: 325.7281\n",
      "Epoch 358/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157138.0781 - mae: 280.5328 - val_loss: 187173.8594 - val_mae: 332.5371\n",
      "Epoch 359/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157706.9375 - mae: 281.6223 - val_loss: 175338.0312 - val_mae: 324.2594\n",
      "Epoch 360/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156519.8594 - mae: 281.7663 - val_loss: 181368.9375 - val_mae: 328.7805\n",
      "Epoch 361/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156457.5000 - mae: 276.6607 - val_loss: 182087.1250 - val_mae: 329.2111\n",
      "Epoch 362/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156417.5000 - mae: 278.2967 - val_loss: 185007.4219 - val_mae: 330.9076\n",
      "Epoch 363/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157404.4375 - mae: 283.8843 - val_loss: 170814.2656 - val_mae: 320.7721\n",
      "Epoch 364/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156183.7344 - mae: 279.5072 - val_loss: 179885.5469 - val_mae: 327.7120\n",
      "Epoch 365/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157220.1875 - mae: 280.1747 - val_loss: 185050.8125 - val_mae: 331.0541\n",
      "Epoch 366/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156419.0156 - mae: 276.6943 - val_loss: 175171.0000 - val_mae: 323.5833\n",
      "Epoch 367/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157385.0938 - mae: 284.5760 - val_loss: 174748.8594 - val_mae: 324.0349\n",
      "Epoch 368/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 154467.9844 - mae: 277.6548 - val_loss: 188044.9062 - val_mae: 333.5132\n",
      "Epoch 369/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157097.5625 - mae: 275.4274 - val_loss: 179285.5625 - val_mae: 327.0128\n",
      "Epoch 370/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155539.3438 - mae: 278.4364 - val_loss: 181612.1406 - val_mae: 328.6293\n",
      "Epoch 371/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157142.1719 - mae: 281.6660 - val_loss: 181018.3125 - val_mae: 328.7238\n",
      "Epoch 372/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156151.8438 - mae: 280.9431 - val_loss: 175738.6406 - val_mae: 324.6072\n",
      "Epoch 373/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 155105.8438 - mae: 278.7423 - val_loss: 178432.6094 - val_mae: 326.6290\n",
      "Epoch 374/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155456.8125 - mae: 277.0096 - val_loss: 181123.7344 - val_mae: 328.3934\n",
      "Epoch 375/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156221.5000 - mae: 281.9164 - val_loss: 182769.4375 - val_mae: 329.3166\n",
      "Epoch 376/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155287.0781 - mae: 275.3544 - val_loss: 184895.0312 - val_mae: 331.0619\n",
      "Epoch 377/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154911.0469 - mae: 277.0496 - val_loss: 178486.7656 - val_mae: 326.7842\n",
      "Epoch 378/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 156599.5469 - mae: 283.3358 - val_loss: 173588.7969 - val_mae: 322.7984\n",
      "Epoch 379/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158250.1875 - mae: 276.0934 - val_loss: 196302.6562 - val_mae: 339.3315\n",
      "Epoch 380/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153424.5000 - mae: 275.4408 - val_loss: 175478.9375 - val_mae: 324.4282\n",
      "Epoch 381/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155772.7031 - mae: 281.2777 - val_loss: 171780.2031 - val_mae: 321.8810\n",
      "Epoch 382/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 156577.7500 - mae: 278.1010 - val_loss: 178792.3281 - val_mae: 327.0858\n",
      "Epoch 383/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 155415.5156 - mae: 282.5304 - val_loss: 172687.3281 - val_mae: 322.6754\n",
      "Epoch 384/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154286.9375 - mae: 278.4239 - val_loss: 180814.7344 - val_mae: 328.6844\n",
      "Epoch 385/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159530.8438 - mae: 276.5517 - val_loss: 179826.8125 - val_mae: 327.6309\n",
      "Epoch 386/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154674.9375 - mae: 280.1172 - val_loss: 175049.9844 - val_mae: 324.1376\n",
      "Epoch 387/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156229.6875 - mae: 279.1859 - val_loss: 173166.1406 - val_mae: 322.9174\n",
      "Epoch 388/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157122.4219 - mae: 277.8493 - val_loss: 177875.9844 - val_mae: 326.8766\n",
      "Epoch 389/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157127.6250 - mae: 284.3973 - val_loss: 180213.0781 - val_mae: 328.2942\n",
      "Epoch 390/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155583.5781 - mae: 275.2823 - val_loss: 181012.8125 - val_mae: 328.7017\n",
      "Epoch 391/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 156761.4375 - mae: 282.6927 - val_loss: 179347.5312 - val_mae: 327.3618\n",
      "Epoch 392/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153965.5312 - mae: 276.1007 - val_loss: 185353.8125 - val_mae: 331.4431\n",
      "Epoch 393/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155431.7188 - mae: 280.3289 - val_loss: 178096.3438 - val_mae: 326.7612\n",
      "Epoch 394/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 155025.8281 - mae: 276.6262 - val_loss: 183088.2969 - val_mae: 330.3142\n",
      "Epoch 395/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 155593.0312 - mae: 281.5236 - val_loss: 176745.2188 - val_mae: 325.9779\n",
      "Epoch 396/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154741.9062 - mae: 274.4637 - val_loss: 189000.7188 - val_mae: 334.2588\n",
      "Epoch 397/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 155357.3438 - mae: 281.4479 - val_loss: 176884.5469 - val_mae: 325.3955\n",
      "Epoch 398/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156458.5625 - mae: 275.4920 - val_loss: 184635.7344 - val_mae: 331.2251\n",
      "Epoch 399/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156895.3750 - mae: 285.3984 - val_loss: 173926.8281 - val_mae: 323.4854\n",
      "Epoch 400/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154899.3750 - mae: 275.9168 - val_loss: 184482.5000 - val_mae: 331.2531\n",
      "Epoch 401/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153835.4531 - mae: 278.1148 - val_loss: 174363.6875 - val_mae: 324.2103\n",
      "Epoch 402/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153306.0156 - mae: 279.6159 - val_loss: 181266.2500 - val_mae: 329.3204\n",
      "Epoch 403/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155116.1406 - mae: 277.0951 - val_loss: 177710.5469 - val_mae: 326.6879\n",
      "Epoch 404/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153873.7812 - mae: 278.2413 - val_loss: 180709.1875 - val_mae: 328.4100\n",
      "Epoch 405/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153945.0625 - mae: 277.8650 - val_loss: 181949.2656 - val_mae: 329.3162\n",
      "Epoch 406/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154211.8125 - mae: 276.7103 - val_loss: 183907.1250 - val_mae: 331.2355\n",
      "Epoch 407/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154130.6406 - mae: 277.6838 - val_loss: 182576.3281 - val_mae: 329.6644\n",
      "Epoch 408/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154346.7031 - mae: 278.2274 - val_loss: 178235.6562 - val_mae: 326.8136\n",
      "Epoch 409/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 154300.4375 - mae: 275.1599 - val_loss: 178552.1719 - val_mae: 326.9244\n",
      "Epoch 410/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153755.5156 - mae: 278.5435 - val_loss: 182514.7969 - val_mae: 329.8217\n",
      "Epoch 411/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152782.5781 - mae: 275.6282 - val_loss: 180690.5938 - val_mae: 328.6629\n",
      "Epoch 412/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155921.8594 - mae: 280.8629 - val_loss: 189273.2344 - val_mae: 334.8449\n",
      "Epoch 413/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 153367.7500 - mae: 274.0368 - val_loss: 177712.9531 - val_mae: 326.2285\n",
      "Epoch 414/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154399.0625 - mae: 275.2394 - val_loss: 180300.3281 - val_mae: 328.7829\n",
      "Epoch 415/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153810.2344 - mae: 277.8392 - val_loss: 179890.5312 - val_mae: 327.9139\n",
      "Epoch 416/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156388.5938 - mae: 283.4447 - val_loss: 173767.6875 - val_mae: 323.6914\n",
      "Epoch 417/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154324.4375 - mae: 276.9739 - val_loss: 184964.5000 - val_mae: 331.6406\n",
      "Epoch 418/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153342.1875 - mae: 275.4039 - val_loss: 181621.9531 - val_mae: 329.1496\n",
      "Epoch 419/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153456.6094 - mae: 273.8307 - val_loss: 181744.3594 - val_mae: 329.1794\n",
      "Epoch 420/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153249.5156 - mae: 279.2030 - val_loss: 175894.0156 - val_mae: 325.0624\n",
      "Epoch 421/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154644.3594 - mae: 274.5763 - val_loss: 184190.6562 - val_mae: 331.0153\n",
      "Epoch 422/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153975.0312 - mae: 281.0059 - val_loss: 170671.3125 - val_mae: 320.9327\n",
      "Epoch 423/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153669.8438 - mae: 277.7260 - val_loss: 181259.2812 - val_mae: 328.7204\n",
      "Epoch 424/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153101.1875 - mae: 276.7513 - val_loss: 179177.5000 - val_mae: 327.3435\n",
      "Epoch 425/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153089.0312 - mae: 276.1076 - val_loss: 182368.5312 - val_mae: 329.7307\n",
      "Epoch 426/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153805.1875 - mae: 279.9409 - val_loss: 182128.9375 - val_mae: 329.3355\n",
      "Epoch 427/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 154729.4375 - mae: 272.7028 - val_loss: 185439.3438 - val_mae: 331.6948\n",
      "Epoch 428/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153872.7656 - mae: 280.3690 - val_loss: 173912.2500 - val_mae: 323.2946\n",
      "Epoch 429/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 152670.0625 - mae: 274.7471 - val_loss: 185501.6250 - val_mae: 332.0940\n",
      "Epoch 430/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153874.7500 - mae: 278.9216 - val_loss: 179964.8125 - val_mae: 328.1477\n",
      "Epoch 431/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151987.8594 - mae: 274.8269 - val_loss: 181241.3438 - val_mae: 329.0139\n",
      "Epoch 432/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151980.7188 - mae: 275.9117 - val_loss: 176155.4062 - val_mae: 325.1632\n",
      "Epoch 433/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152086.9844 - mae: 274.6378 - val_loss: 182635.9219 - val_mae: 329.4615\n",
      "Epoch 434/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153092.3750 - mae: 274.5096 - val_loss: 176005.5781 - val_mae: 325.0424\n",
      "Epoch 435/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 153434.5000 - mae: 280.2859 - val_loss: 174932.1094 - val_mae: 324.5368\n",
      "Epoch 436/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152896.9375 - mae: 274.4954 - val_loss: 176809.1875 - val_mae: 325.3567\n",
      "Epoch 437/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153104.0781 - mae: 272.9373 - val_loss: 184117.2656 - val_mae: 330.7794\n",
      "Epoch 438/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151160.7500 - mae: 274.8954 - val_loss: 170977.4531 - val_mae: 321.1252\n",
      "Epoch 439/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152515.4375 - mae: 277.2988 - val_loss: 183817.7500 - val_mae: 330.3615\n",
      "Epoch 440/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151628.8906 - mae: 273.4232 - val_loss: 180213.1719 - val_mae: 327.9841\n",
      "Epoch 441/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155347.3906 - mae: 283.8761 - val_loss: 171421.2969 - val_mae: 321.1337\n",
      "Epoch 442/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 150925.5312 - mae: 273.8342 - val_loss: 187483.5156 - val_mae: 333.5150\n",
      "Epoch 443/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 156035.3125 - mae: 270.5068 - val_loss: 183631.1094 - val_mae: 330.2169\n",
      "Epoch 444/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 152642.0938 - mae: 281.9332 - val_loss: 168163.5625 - val_mae: 319.1337\n",
      "Epoch 445/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151304.7188 - mae: 277.6206 - val_loss: 184004.6562 - val_mae: 330.7504\n",
      "Epoch 446/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151700.8438 - mae: 274.7834 - val_loss: 177113.8594 - val_mae: 324.9886\n",
      "Epoch 447/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 151050.6719 - mae: 273.6100 - val_loss: 179014.5781 - val_mae: 326.7581\n",
      "Epoch 448/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 152714.1094 - mae: 277.4655 - val_loss: 180252.4688 - val_mae: 327.2367\n",
      "Epoch 449/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151469.3594 - mae: 270.6599 - val_loss: 185014.6250 - val_mae: 331.0424\n",
      "Epoch 450/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156673.6250 - mae: 282.5491 - val_loss: 177370.8438 - val_mae: 325.6185\n",
      "Epoch 451/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154008.3281 - mae: 270.1667 - val_loss: 184977.8906 - val_mae: 331.2137\n",
      "Epoch 452/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152022.8125 - mae: 273.9385 - val_loss: 181952.6562 - val_mae: 328.6601\n",
      "Epoch 453/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 151713.9688 - mae: 275.8820 - val_loss: 173194.0000 - val_mae: 322.1116\n",
      "Epoch 454/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 155316.9375 - mae: 272.6660 - val_loss: 174892.0156 - val_mae: 323.2640\n",
      "Epoch 455/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151687.2188 - mae: 273.8572 - val_loss: 172168.1094 - val_mae: 321.4081\n",
      "Epoch 456/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151074.6875 - mae: 277.8348 - val_loss: 174631.3125 - val_mae: 322.5697\n",
      "Epoch 457/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151875.0156 - mae: 271.7120 - val_loss: 180635.3125 - val_mae: 327.2618\n",
      "Epoch 458/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152217.9844 - mae: 277.3925 - val_loss: 174413.1562 - val_mae: 323.1475\n",
      "Epoch 459/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 149747.9531 - mae: 272.2085 - val_loss: 191428.8750 - val_mae: 335.9742\n",
      "Epoch 460/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150776.6719 - mae: 271.3447 - val_loss: 183843.0625 - val_mae: 330.1008\n",
      "Epoch 461/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 150554.8438 - mae: 270.7209 - val_loss: 175240.3594 - val_mae: 322.9756\n",
      "Epoch 462/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150956.7031 - mae: 272.4233 - val_loss: 175322.0156 - val_mae: 323.1629\n",
      "Epoch 463/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 150484.5781 - mae: 271.3993 - val_loss: 179633.8281 - val_mae: 326.6826\n",
      "Epoch 464/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150413.1875 - mae: 269.2038 - val_loss: 185589.0938 - val_mae: 331.3252\n",
      "Epoch 465/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153035.8594 - mae: 278.4143 - val_loss: 172756.7031 - val_mae: 321.5391\n",
      "Epoch 466/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151071.6250 - mae: 267.9923 - val_loss: 183522.6406 - val_mae: 329.4293\n",
      "Epoch 467/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 150019.2969 - mae: 271.3883 - val_loss: 176470.0781 - val_mae: 324.0703\n",
      "Epoch 468/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150775.8281 - mae: 276.5783 - val_loss: 175894.7656 - val_mae: 323.9858\n",
      "Epoch 469/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149686.2812 - mae: 274.0563 - val_loss: 182209.2812 - val_mae: 328.5464\n",
      "Epoch 470/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153417.5625 - mae: 265.8243 - val_loss: 188512.3750 - val_mae: 333.7052\n",
      "Epoch 471/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150219.2344 - mae: 272.5047 - val_loss: 170964.6562 - val_mae: 319.8283\n",
      "Epoch 472/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 152013.6719 - mae: 272.6422 - val_loss: 182948.1875 - val_mae: 329.0497\n",
      "Epoch 473/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149202.7031 - mae: 270.0645 - val_loss: 174325.7188 - val_mae: 322.4041\n",
      "Epoch 474/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 150740.5625 - mae: 275.1053 - val_loss: 173875.7031 - val_mae: 322.2068\n",
      "Epoch 475/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149505.9531 - mae: 270.6978 - val_loss: 180523.1875 - val_mae: 327.2789\n",
      "Epoch 476/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150447.5000 - mae: 266.7793 - val_loss: 176947.7188 - val_mae: 324.5342\n",
      "Epoch 477/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150586.1719 - mae: 277.1529 - val_loss: 173720.0000 - val_mae: 322.3397\n",
      "Epoch 478/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148831.6875 - mae: 269.4448 - val_loss: 181472.7031 - val_mae: 328.2097\n",
      "Epoch 479/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149424.3125 - mae: 267.6779 - val_loss: 179147.4844 - val_mae: 326.1996\n",
      "Epoch 480/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150166.2031 - mae: 269.4385 - val_loss: 176632.4375 - val_mae: 323.9071\n",
      "Epoch 481/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149822.7812 - mae: 270.2560 - val_loss: 178139.6094 - val_mae: 325.5229\n",
      "Epoch 482/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149581.2031 - mae: 273.9246 - val_loss: 173565.3281 - val_mae: 322.3124\n",
      "Epoch 483/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 149653.6875 - mae: 268.8863 - val_loss: 179427.7188 - val_mae: 326.3322\n",
      "Epoch 484/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148841.0312 - mae: 270.3373 - val_loss: 179134.3750 - val_mae: 325.8893\n",
      "Epoch 485/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148997.7500 - mae: 269.6721 - val_loss: 181415.1719 - val_mae: 327.8810\n",
      "Epoch 486/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149192.8281 - mae: 271.8617 - val_loss: 176906.4531 - val_mae: 324.3155\n",
      "Epoch 487/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148337.6719 - mae: 267.6881 - val_loss: 183793.3125 - val_mae: 330.0045\n",
      "Epoch 488/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150647.5156 - mae: 270.2747 - val_loss: 178338.1875 - val_mae: 325.3836\n",
      "Epoch 489/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148934.9375 - mae: 270.6825 - val_loss: 182235.1875 - val_mae: 328.8219\n",
      "Epoch 490/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148481.8438 - mae: 268.1669 - val_loss: 177311.2969 - val_mae: 324.2438\n",
      "Epoch 491/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149925.2500 - mae: 268.5382 - val_loss: 173526.0000 - val_mae: 321.9449\n",
      "Epoch 492/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148803.2031 - mae: 274.0977 - val_loss: 172044.2656 - val_mae: 321.0688\n",
      "Epoch 493/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148675.8906 - mae: 267.9273 - val_loss: 180975.8906 - val_mae: 327.3105\n",
      "Epoch 494/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148855.3906 - mae: 266.5749 - val_loss: 180698.4375 - val_mae: 327.2214\n",
      "Epoch 495/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148835.4062 - mae: 267.2696 - val_loss: 179650.1250 - val_mae: 326.5697\n",
      "Epoch 496/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149206.4375 - mae: 276.2254 - val_loss: 172332.4531 - val_mae: 320.9077\n",
      "Epoch 497/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149827.4375 - mae: 271.6709 - val_loss: 187938.0000 - val_mae: 333.5394\n",
      "Epoch 498/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148420.0000 - mae: 267.0100 - val_loss: 180119.3281 - val_mae: 327.0316\n",
      "Epoch 499/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148612.3125 - mae: 271.2560 - val_loss: 175103.6875 - val_mae: 322.6510\n",
      "Epoch 500/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149159.3906 - mae: 267.8063 - val_loss: 177640.2031 - val_mae: 324.7460\n",
      "Epoch 501/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153883.3125 - mae: 278.7735 - val_loss: 171160.5312 - val_mae: 320.1353\n",
      "Epoch 502/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149187.6719 - mae: 265.6974 - val_loss: 188143.7969 - val_mae: 333.6676\n",
      "Epoch 503/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149377.4688 - mae: 270.6987 - val_loss: 174456.6406 - val_mae: 322.0988\n",
      "Epoch 504/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148889.5625 - mae: 269.6830 - val_loss: 182285.1250 - val_mae: 328.6433\n",
      "Epoch 505/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 149641.6406 - mae: 264.4681 - val_loss: 187269.5312 - val_mae: 332.7999\n",
      "Epoch 506/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147721.3594 - mae: 270.0647 - val_loss: 173967.9375 - val_mae: 321.7044\n",
      "Epoch 507/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148100.6250 - mae: 268.2269 - val_loss: 180010.8125 - val_mae: 326.5127\n",
      "Epoch 508/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148145.0469 - mae: 267.3107 - val_loss: 182662.8906 - val_mae: 329.0427\n",
      "Epoch 509/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146670.5312 - mae: 268.0932 - val_loss: 170372.1406 - val_mae: 319.0416\n",
      "Epoch 510/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148693.4531 - mae: 275.9249 - val_loss: 174701.3906 - val_mae: 323.1449\n",
      "Epoch 511/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149497.0938 - mae: 267.0974 - val_loss: 183907.5625 - val_mae: 329.5779\n",
      "Epoch 512/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 147310.5781 - mae: 266.6940 - val_loss: 181470.2344 - val_mae: 328.1974\n",
      "Epoch 513/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147046.0938 - mae: 269.2916 - val_loss: 177735.0625 - val_mae: 324.8407\n",
      "Epoch 514/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 147985.1250 - mae: 265.5458 - val_loss: 178732.4375 - val_mae: 325.5121\n",
      "Epoch 515/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147927.0312 - mae: 272.6273 - val_loss: 176849.0312 - val_mae: 324.0537\n",
      "Epoch 516/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 147002.4062 - mae: 267.9088 - val_loss: 181307.4219 - val_mae: 327.6489\n",
      "Epoch 517/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146869.0781 - mae: 266.2447 - val_loss: 175885.7656 - val_mae: 322.9945\n",
      "Epoch 518/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149549.4375 - mae: 264.3854 - val_loss: 175941.0938 - val_mae: 322.7969\n",
      "Epoch 519/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 147421.2656 - mae: 271.3052 - val_loss: 176116.4531 - val_mae: 323.4612\n",
      "Epoch 520/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146944.1094 - mae: 266.7622 - val_loss: 182895.3438 - val_mae: 328.8730\n",
      "Epoch 521/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146716.5312 - mae: 269.8846 - val_loss: 173612.5781 - val_mae: 321.2448\n",
      "Epoch 522/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146465.9219 - mae: 268.9458 - val_loss: 178364.0156 - val_mae: 325.0465\n",
      "Epoch 523/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146503.9219 - mae: 264.4108 - val_loss: 182872.0781 - val_mae: 328.6849\n",
      "Epoch 524/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147091.9531 - mae: 269.3645 - val_loss: 178755.1094 - val_mae: 325.2607\n",
      "Epoch 525/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148495.0625 - mae: 264.4644 - val_loss: 179869.2188 - val_mae: 326.0225\n",
      "Epoch 526/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147703.1094 - mae: 264.6417 - val_loss: 174502.9375 - val_mae: 321.5633\n",
      "Epoch 527/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146477.4219 - mae: 270.2467 - val_loss: 173217.0156 - val_mae: 321.3200\n",
      "Epoch 528/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148022.3438 - mae: 267.8802 - val_loss: 181602.5625 - val_mae: 327.9037\n",
      "Epoch 529/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146279.2500 - mae: 266.4303 - val_loss: 177463.2656 - val_mae: 324.7865\n",
      "Epoch 530/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146860.5781 - mae: 272.1111 - val_loss: 176056.2812 - val_mae: 323.2582\n",
      "Epoch 531/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148908.2188 - mae: 263.7050 - val_loss: 186723.2188 - val_mae: 331.9553\n",
      "Epoch 532/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144571.4844 - mae: 265.3751 - val_loss: 172045.8750 - val_mae: 319.4171\n",
      "Epoch 533/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 146916.0312 - mae: 273.5084 - val_loss: 170962.6406 - val_mae: 319.1902\n",
      "Epoch 534/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 147812.8906 - mae: 264.9982 - val_loss: 184151.6875 - val_mae: 329.7589\n",
      "Epoch 535/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145220.3281 - mae: 265.2307 - val_loss: 174162.2969 - val_mae: 321.3850\n",
      "Epoch 536/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146978.5938 - mae: 272.3983 - val_loss: 181683.7188 - val_mae: 327.9897\n",
      "Epoch 537/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 145805.5312 - mae: 262.9876 - val_loss: 183714.0625 - val_mae: 329.1407\n",
      "Epoch 538/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144963.6875 - mae: 265.6398 - val_loss: 175291.6406 - val_mae: 322.1925\n",
      "Epoch 539/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147490.6250 - mae: 270.9306 - val_loss: 184293.0625 - val_mae: 329.9120\n",
      "Epoch 540/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145530.3125 - mae: 263.8829 - val_loss: 181528.7188 - val_mae: 327.6430\n",
      "Epoch 541/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145784.5469 - mae: 268.1212 - val_loss: 176492.2656 - val_mae: 322.7729\n",
      "Epoch 542/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145907.9688 - mae: 263.0399 - val_loss: 181829.8438 - val_mae: 327.8611\n",
      "Epoch 543/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145856.8438 - mae: 268.5718 - val_loss: 178512.1094 - val_mae: 324.8071\n",
      "Epoch 544/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145441.3125 - mae: 264.9108 - val_loss: 179520.3125 - val_mae: 326.1401\n",
      "Epoch 545/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145069.0312 - mae: 266.5134 - val_loss: 176822.5938 - val_mae: 323.2319\n",
      "Epoch 546/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145215.1406 - mae: 267.2874 - val_loss: 176348.2812 - val_mae: 323.6127\n",
      "Epoch 547/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146295.6406 - mae: 263.7085 - val_loss: 187923.2344 - val_mae: 332.7183\n",
      "Epoch 548/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144790.7031 - mae: 263.6703 - val_loss: 172688.7031 - val_mae: 320.4495\n",
      "Epoch 549/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145405.5000 - mae: 269.9056 - val_loss: 173769.7344 - val_mae: 321.2673\n",
      "Epoch 550/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 147554.7344 - mae: 266.2281 - val_loss: 178593.1719 - val_mae: 325.1396\n",
      "Epoch 551/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148385.7656 - mae: 273.2976 - val_loss: 187421.1250 - val_mae: 332.4851\n",
      "Epoch 552/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145698.9688 - mae: 262.6962 - val_loss: 183438.5312 - val_mae: 329.0574\n",
      "Epoch 553/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149251.8281 - mae: 273.8645 - val_loss: 178577.0000 - val_mae: 325.1550\n",
      "Epoch 554/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149076.9062 - mae: 262.8334 - val_loss: 183972.2031 - val_mae: 329.5717\n",
      "Epoch 555/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144145.1719 - mae: 265.9643 - val_loss: 169944.1719 - val_mae: 318.1171\n",
      "Epoch 556/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146761.5625 - mae: 264.3521 - val_loss: 179969.6562 - val_mae: 326.4547\n",
      "Epoch 557/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145745.4062 - mae: 269.8860 - val_loss: 174911.4688 - val_mae: 322.1078\n",
      "Epoch 558/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146287.7969 - mae: 263.2478 - val_loss: 178796.0312 - val_mae: 325.5724\n",
      "Epoch 559/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 146251.7812 - mae: 266.9234 - val_loss: 177690.9219 - val_mae: 323.7416\n",
      "Epoch 560/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144835.6875 - mae: 265.3694 - val_loss: 184771.4688 - val_mae: 330.3406\n",
      "Epoch 561/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144789.7344 - mae: 263.2037 - val_loss: 172013.8438 - val_mae: 319.9077\n",
      "Epoch 562/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144160.7344 - mae: 266.8310 - val_loss: 175321.4375 - val_mae: 322.4156\n",
      "Epoch 563/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146840.0469 - mae: 263.1442 - val_loss: 181878.3750 - val_mae: 327.5907\n",
      "Epoch 564/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 147575.3125 - mae: 271.2762 - val_loss: 177710.5156 - val_mae: 323.9767\n",
      "Epoch 565/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145006.9688 - mae: 265.5759 - val_loss: 179137.8125 - val_mae: 325.4656\n",
      "Epoch 566/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144092.7812 - mae: 262.4080 - val_loss: 182950.9062 - val_mae: 328.8229\n",
      "Epoch 567/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 147908.6094 - mae: 272.2138 - val_loss: 180763.9219 - val_mae: 326.9059\n",
      "Epoch 568/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145185.4844 - mae: 260.1321 - val_loss: 191509.5156 - val_mae: 335.6597\n",
      "Epoch 569/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 143750.5469 - mae: 263.3214 - val_loss: 176916.7969 - val_mae: 323.4642\n",
      "Epoch 570/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143382.3906 - mae: 263.8828 - val_loss: 179606.3594 - val_mae: 325.5867\n",
      "Epoch 571/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143851.1094 - mae: 264.4577 - val_loss: 185973.8906 - val_mae: 331.5462\n",
      "Epoch 572/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144151.4375 - mae: 262.8028 - val_loss: 175438.5625 - val_mae: 321.9404\n",
      "Epoch 573/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144054.6875 - mae: 264.5926 - val_loss: 182746.5156 - val_mae: 328.7402\n",
      "Epoch 574/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 143586.0312 - mae: 261.7928 - val_loss: 180235.6719 - val_mae: 326.4060\n",
      "Epoch 575/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144299.3125 - mae: 268.3060 - val_loss: 172769.5312 - val_mae: 319.4957\n",
      "Epoch 576/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144292.0000 - mae: 262.6384 - val_loss: 178636.3906 - val_mae: 324.7804\n",
      "Epoch 577/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143485.9375 - mae: 262.7477 - val_loss: 177634.4062 - val_mae: 324.0063\n",
      "Epoch 578/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143249.7969 - mae: 264.8759 - val_loss: 178688.2656 - val_mae: 324.9081\n",
      "Epoch 579/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 143647.8906 - mae: 265.8315 - val_loss: 179401.6875 - val_mae: 325.5791\n",
      "Epoch 580/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143401.6406 - mae: 259.4296 - val_loss: 186749.6250 - val_mae: 331.2299\n",
      "Epoch 581/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145694.1562 - mae: 269.9062 - val_loss: 175356.8594 - val_mae: 321.7177\n",
      "Epoch 582/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145365.6094 - mae: 260.5613 - val_loss: 191938.0469 - val_mae: 335.1437\n",
      "Epoch 583/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149723.3281 - mae: 276.0221 - val_loss: 176128.9531 - val_mae: 322.4948\n",
      "Epoch 584/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143772.6875 - mae: 260.9173 - val_loss: 187451.0312 - val_mae: 331.9120\n",
      "Epoch 585/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142293.9219 - mae: 260.2201 - val_loss: 173212.5625 - val_mae: 319.7220\n",
      "Epoch 586/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145447.0781 - mae: 272.5999 - val_loss: 175598.9062 - val_mae: 321.8434\n",
      "Epoch 587/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142665.3750 - mae: 261.9586 - val_loss: 189538.2188 - val_mae: 333.5319\n",
      "Epoch 588/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143898.8125 - mae: 259.2462 - val_loss: 185331.3125 - val_mae: 330.1674\n",
      "Epoch 589/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142528.9062 - mae: 265.5825 - val_loss: 172361.1875 - val_mae: 319.8842\n",
      "Epoch 590/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143817.0625 - mae: 265.5273 - val_loss: 178998.8438 - val_mae: 325.1482\n",
      "Epoch 591/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142412.3125 - mae: 262.7992 - val_loss: 183870.8438 - val_mae: 329.2784\n",
      "Epoch 592/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143128.3750 - mae: 262.5018 - val_loss: 185455.3438 - val_mae: 330.1522\n",
      "Epoch 593/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 141747.5156 - mae: 259.7508 - val_loss: 177812.2344 - val_mae: 324.0948\n",
      "Epoch 594/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142302.7969 - mae: 264.8116 - val_loss: 176052.8125 - val_mae: 321.9391\n",
      "Epoch 595/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 142721.1875 - mae: 259.9586 - val_loss: 183488.4531 - val_mae: 328.4565\n",
      "Epoch 596/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141714.9688 - mae: 262.9674 - val_loss: 174840.7812 - val_mae: 321.2714\n",
      "Epoch 597/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141442.6875 - mae: 261.7109 - val_loss: 184423.6875 - val_mae: 329.3546\n",
      "Epoch 598/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141661.7500 - mae: 261.5034 - val_loss: 179173.0938 - val_mae: 324.9317\n",
      "Epoch 599/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141892.9688 - mae: 260.2080 - val_loss: 179829.5625 - val_mae: 325.6540\n",
      "Epoch 600/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142570.4531 - mae: 263.3230 - val_loss: 185189.7031 - val_mae: 330.2935\n",
      "Epoch 601/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141756.6875 - mae: 262.6191 - val_loss: 180596.1094 - val_mae: 326.0923\n",
      "Epoch 602/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144990.0625 - mae: 259.9377 - val_loss: 175044.8125 - val_mae: 320.8241\n",
      "Epoch 603/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 142573.8906 - mae: 261.0034 - val_loss: 174841.1250 - val_mae: 320.8545\n",
      "Epoch 604/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143385.1875 - mae: 266.5120 - val_loss: 184501.6406 - val_mae: 329.6512\n",
      "Epoch 605/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 142536.5938 - mae: 264.9083 - val_loss: 171935.6875 - val_mae: 318.7501\n",
      "Epoch 606/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141091.7969 - mae: 259.8257 - val_loss: 189993.6406 - val_mae: 333.6111\n",
      "Epoch 607/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142264.8750 - mae: 255.6692 - val_loss: 181414.2188 - val_mae: 326.6629\n",
      "Epoch 608/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145941.7031 - mae: 274.0048 - val_loss: 179064.2812 - val_mae: 324.9415\n",
      "Epoch 609/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141172.3438 - mae: 260.3617 - val_loss: 187582.6094 - val_mae: 331.6328\n",
      "Epoch 610/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141320.9688 - mae: 259.2133 - val_loss: 180411.0312 - val_mae: 325.6848\n",
      "Epoch 611/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142305.1406 - mae: 260.7098 - val_loss: 172906.7969 - val_mae: 318.9839\n",
      "Epoch 612/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 140620.0312 - mae: 262.0452 - val_loss: 183354.4844 - val_mae: 328.0789\n",
      "Epoch 613/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141574.5156 - mae: 258.3937 - val_loss: 186069.4062 - val_mae: 330.1071\n",
      "Epoch 614/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140377.9688 - mae: 258.9403 - val_loss: 181464.8125 - val_mae: 326.8674\n",
      "Epoch 615/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 141676.8906 - mae: 264.5548 - val_loss: 176704.3125 - val_mae: 321.9624\n",
      "Epoch 616/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140417.3125 - mae: 260.8142 - val_loss: 187097.9375 - val_mae: 330.7990\n",
      "Epoch 617/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141328.3438 - mae: 258.4808 - val_loss: 185394.8750 - val_mae: 329.3470\n",
      "Epoch 618/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141492.3281 - mae: 262.2706 - val_loss: 173517.5156 - val_mae: 319.6018\n",
      "Epoch 619/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 142120.8594 - mae: 257.8382 - val_loss: 186073.4688 - val_mae: 329.8871\n",
      "Epoch 620/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141411.4531 - mae: 263.8236 - val_loss: 176365.9375 - val_mae: 321.6723\n",
      "Epoch 621/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141594.5156 - mae: 257.6205 - val_loss: 186718.1719 - val_mae: 330.2748\n",
      "Epoch 622/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 143153.8438 - mae: 267.7194 - val_loss: 179854.8906 - val_mae: 324.7688\n",
      "Epoch 623/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 140210.0781 - mae: 258.1342 - val_loss: 183719.5312 - val_mae: 327.9259\n",
      "Epoch 624/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 140202.9531 - mae: 257.1754 - val_loss: 179718.9688 - val_mae: 324.6608\n",
      "Epoch 625/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141107.7656 - mae: 265.3008 - val_loss: 181660.5781 - val_mae: 326.8904\n",
      "Epoch 626/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139796.2188 - mae: 258.2904 - val_loss: 188664.7344 - val_mae: 332.0837\n",
      "Epoch 627/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 140361.3125 - mae: 257.9780 - val_loss: 177896.6250 - val_mae: 323.1161\n",
      "Epoch 628/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141124.6719 - mae: 260.7797 - val_loss: 185166.2969 - val_mae: 329.7586\n",
      "Epoch 629/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 140625.1875 - mae: 255.8158 - val_loss: 184529.6562 - val_mae: 328.8455\n",
      "Epoch 630/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139366.8125 - mae: 258.8719 - val_loss: 178085.3125 - val_mae: 323.1931\n",
      "Epoch 631/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141883.1719 - mae: 261.6024 - val_loss: 186873.4062 - val_mae: 331.0256\n",
      "Epoch 632/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138895.3594 - mae: 257.3071 - val_loss: 177012.3125 - val_mae: 322.2795\n",
      "Epoch 633/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 139650.8281 - mae: 260.2622 - val_loss: 183246.7031 - val_mae: 327.8717\n",
      "Epoch 634/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139969.4688 - mae: 262.0902 - val_loss: 178945.6406 - val_mae: 323.5797\n",
      "Epoch 635/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139893.6719 - mae: 256.8463 - val_loss: 183031.0312 - val_mae: 327.3401\n",
      "Epoch 636/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140882.1875 - mae: 256.1635 - val_loss: 185368.4531 - val_mae: 328.9960\n",
      "Epoch 637/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138885.2500 - mae: 257.4105 - val_loss: 172054.5938 - val_mae: 318.7627\n",
      "Epoch 638/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 142038.9219 - mae: 258.4360 - val_loss: 184030.2969 - val_mae: 328.5555\n",
      "Epoch 639/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143055.5625 - mae: 269.7285 - val_loss: 184431.1875 - val_mae: 328.6241\n",
      "Epoch 640/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139861.5938 - mae: 260.0181 - val_loss: 180868.8125 - val_mae: 325.3776\n",
      "Epoch 641/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138729.8750 - mae: 256.6089 - val_loss: 186918.4688 - val_mae: 330.6219\n",
      "Epoch 642/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138508.4375 - mae: 256.0422 - val_loss: 180360.5625 - val_mae: 325.2863\n",
      "Epoch 643/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140279.7812 - mae: 263.3746 - val_loss: 178435.3750 - val_mae: 323.1321\n",
      "Epoch 644/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140369.3594 - mae: 257.1703 - val_loss: 178855.3906 - val_mae: 323.2797\n",
      "Epoch 645/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138874.7969 - mae: 256.7165 - val_loss: 184818.8594 - val_mae: 328.7896\n",
      "Epoch 646/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138985.8281 - mae: 256.3527 - val_loss: 184093.5938 - val_mae: 328.0078\n",
      "Epoch 647/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140311.9531 - mae: 257.2280 - val_loss: 185327.1406 - val_mae: 329.1584\n",
      "Epoch 648/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139189.7656 - mae: 263.0175 - val_loss: 174886.1094 - val_mae: 319.9091\n",
      "Epoch 649/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 138519.3906 - mae: 257.6019 - val_loss: 185192.0625 - val_mae: 328.6703\n",
      "Epoch 650/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138414.0469 - mae: 257.2319 - val_loss: 179180.9375 - val_mae: 323.4601\n",
      "Epoch 651/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138625.3594 - mae: 260.1405 - val_loss: 182859.7812 - val_mae: 326.1144\n",
      "Epoch 652/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138612.7344 - mae: 257.7445 - val_loss: 183947.8438 - val_mae: 326.8940\n",
      "Epoch 653/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139141.3594 - mae: 257.7424 - val_loss: 186363.9219 - val_mae: 329.5758\n",
      "Epoch 654/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138052.2812 - mae: 256.1990 - val_loss: 177158.9219 - val_mae: 321.6638\n",
      "Epoch 655/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139713.7500 - mae: 263.0937 - val_loss: 186372.9688 - val_mae: 329.4870\n",
      "Epoch 656/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 138189.9688 - mae: 257.0840 - val_loss: 189089.9062 - val_mae: 331.0333\n",
      "Epoch 657/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137618.7031 - mae: 254.0053 - val_loss: 186224.4219 - val_mae: 328.8439\n",
      "Epoch 658/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138308.5781 - mae: 253.9068 - val_loss: 187733.3750 - val_mae: 330.6579\n",
      "Epoch 659/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138541.7500 - mae: 262.7975 - val_loss: 175679.1875 - val_mae: 320.3152\n",
      "Epoch 660/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137401.2500 - mae: 255.9475 - val_loss: 189835.5469 - val_mae: 331.5055\n",
      "Epoch 661/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139761.2969 - mae: 254.4583 - val_loss: 178535.0625 - val_mae: 322.1091\n",
      "Epoch 662/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138701.4062 - mae: 263.7938 - val_loss: 174105.6094 - val_mae: 319.0212\n",
      "Epoch 663/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137478.1250 - mae: 256.2135 - val_loss: 190523.2344 - val_mae: 332.0494\n",
      "Epoch 664/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138209.8281 - mae: 256.5663 - val_loss: 187903.2031 - val_mae: 329.5362\n",
      "Epoch 665/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141494.6406 - mae: 253.2483 - val_loss: 182138.6719 - val_mae: 325.3673\n",
      "Epoch 666/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139680.3281 - mae: 269.3004 - val_loss: 171457.2031 - val_mae: 317.3708\n",
      "Epoch 667/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140701.4219 - mae: 255.8155 - val_loss: 199578.6719 - val_mae: 339.2846\n",
      "Epoch 668/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137988.0625 - mae: 257.2025 - val_loss: 183340.0938 - val_mae: 326.8232\n",
      "Epoch 669/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136623.0469 - mae: 256.0712 - val_loss: 179238.0312 - val_mae: 322.9697\n",
      "Epoch 670/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140664.2031 - mae: 257.9073 - val_loss: 178986.9844 - val_mae: 322.6344\n",
      "Epoch 671/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137634.0312 - mae: 258.6881 - val_loss: 173528.7188 - val_mae: 318.3560\n",
      "Epoch 672/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137230.1250 - mae: 257.8213 - val_loss: 184516.0938 - val_mae: 327.0963\n",
      "Epoch 673/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 136885.2656 - mae: 255.9408 - val_loss: 177961.6250 - val_mae: 321.2782\n",
      "Epoch 674/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136914.6719 - mae: 259.3080 - val_loss: 182448.4062 - val_mae: 325.4172\n",
      "Epoch 675/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137417.1094 - mae: 252.5384 - val_loss: 182756.4219 - val_mae: 325.4225\n",
      "Epoch 676/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138377.2656 - mae: 260.9594 - val_loss: 181490.5312 - val_mae: 324.2330\n",
      "Epoch 677/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135990.7031 - mae: 255.0397 - val_loss: 191448.5938 - val_mae: 332.4459\n",
      "Epoch 678/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 137260.8281 - mae: 253.4187 - val_loss: 180903.1406 - val_mae: 323.9452\n",
      "Epoch 679/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137169.7656 - mae: 257.3352 - val_loss: 181511.7969 - val_mae: 324.0381\n",
      "Epoch 680/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136533.0781 - mae: 255.2927 - val_loss: 181342.8906 - val_mae: 323.9169\n",
      "Epoch 681/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137770.1875 - mae: 251.4827 - val_loss: 194191.8438 - val_mae: 334.4639\n",
      "Epoch 682/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 136083.1875 - mae: 257.9350 - val_loss: 174786.1719 - val_mae: 318.9223\n",
      "Epoch 683/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 137902.8125 - mae: 253.8015 - val_loss: 182193.7500 - val_mae: 324.9569\n",
      "Epoch 684/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136906.6719 - mae: 259.5683 - val_loss: 188543.3125 - val_mae: 329.9176\n",
      "Epoch 685/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135292.9062 - mae: 253.0500 - val_loss: 180688.0625 - val_mae: 323.4009\n",
      "Epoch 686/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 136283.0625 - mae: 258.0933 - val_loss: 183302.8750 - val_mae: 325.4527\n",
      "Epoch 687/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 136994.5938 - mae: 253.1408 - val_loss: 181495.4219 - val_mae: 323.6662\n",
      "Epoch 688/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137688.0000 - mae: 253.1922 - val_loss: 186452.8125 - val_mae: 327.7176\n",
      "Epoch 689/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138071.2969 - mae: 257.3482 - val_loss: 174063.5625 - val_mae: 319.1299\n",
      "Epoch 690/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137889.1094 - mae: 264.4410 - val_loss: 183677.1250 - val_mae: 325.7268\n",
      "Epoch 691/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135080.3125 - mae: 255.1144 - val_loss: 189315.7812 - val_mae: 329.7518\n",
      "Epoch 692/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135839.6719 - mae: 252.7800 - val_loss: 184920.5938 - val_mae: 326.4303\n",
      "Epoch 693/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135006.0625 - mae: 255.9468 - val_loss: 177624.0469 - val_mae: 320.9797\n",
      "Epoch 694/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134838.9531 - mae: 256.8799 - val_loss: 186396.9688 - val_mae: 327.9704\n",
      "Epoch 695/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134555.2188 - mae: 252.1115 - val_loss: 185321.8594 - val_mae: 326.4409\n",
      "Epoch 696/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136049.3125 - mae: 251.5172 - val_loss: 184261.3750 - val_mae: 325.7802\n",
      "Epoch 697/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 135498.3281 - mae: 260.1073 - val_loss: 182420.4219 - val_mae: 324.9377\n",
      "Epoch 698/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134611.0312 - mae: 256.3783 - val_loss: 185009.4688 - val_mae: 326.4788\n",
      "Epoch 699/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 135704.3281 - mae: 252.3172 - val_loss: 181159.0312 - val_mae: 323.3036\n",
      "Epoch 700/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 136571.6875 - mae: 259.9416 - val_loss: 174233.6719 - val_mae: 318.2543\n",
      "Epoch 701/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133186.5000 - mae: 252.7130 - val_loss: 194980.5781 - val_mae: 333.7371\n",
      "Epoch 702/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138050.1719 - mae: 259.9052 - val_loss: 186284.6406 - val_mae: 327.4669\n",
      "Epoch 703/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135788.3125 - mae: 250.9823 - val_loss: 191656.4844 - val_mae: 330.7291\n",
      "Epoch 704/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 134743.2656 - mae: 257.4056 - val_loss: 176059.3125 - val_mae: 319.4673\n",
      "Epoch 705/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133629.9844 - mae: 254.3965 - val_loss: 185681.2969 - val_mae: 326.8346\n",
      "Epoch 706/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134225.2344 - mae: 249.4805 - val_loss: 187467.1875 - val_mae: 327.8277\n",
      "Epoch 707/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 133647.6875 - mae: 252.9162 - val_loss: 180614.6562 - val_mae: 323.1784\n",
      "Epoch 708/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133915.9844 - mae: 258.3337 - val_loss: 180946.6875 - val_mae: 323.1961\n",
      "Epoch 709/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133850.9531 - mae: 252.0144 - val_loss: 188542.2344 - val_mae: 328.8080\n",
      "Epoch 710/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133299.5938 - mae: 253.2629 - val_loss: 185186.3750 - val_mae: 325.9218\n",
      "Epoch 711/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134965.9375 - mae: 250.0257 - val_loss: 181946.2969 - val_mae: 323.7071\n",
      "Epoch 712/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133813.1875 - mae: 255.9821 - val_loss: 180294.4375 - val_mae: 322.3646\n",
      "Epoch 713/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133197.8281 - mae: 251.3101 - val_loss: 187556.1094 - val_mae: 327.6456\n",
      "Epoch 714/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 132684.2031 - mae: 249.4675 - val_loss: 183389.1250 - val_mae: 324.7479\n",
      "Epoch 715/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132707.1719 - mae: 253.7450 - val_loss: 180770.6719 - val_mae: 322.8230\n",
      "Epoch 716/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133157.4531 - mae: 251.9963 - val_loss: 186359.7344 - val_mae: 326.9267\n",
      "Epoch 717/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132546.5938 - mae: 252.1182 - val_loss: 182067.5625 - val_mae: 323.8040\n",
      "Epoch 718/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 132647.2969 - mae: 254.1828 - val_loss: 187504.9531 - val_mae: 327.9023\n",
      "Epoch 719/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 135094.7812 - mae: 257.8200 - val_loss: 191199.3125 - val_mae: 330.0648\n",
      "Epoch 720/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134781.7344 - mae: 247.2339 - val_loss: 188784.3281 - val_mae: 328.8011\n",
      "Epoch 721/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134762.1406 - mae: 259.9929 - val_loss: 174347.1875 - val_mae: 317.9483\n",
      "Epoch 722/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133240.4375 - mae: 250.2731 - val_loss: 195079.0781 - val_mae: 332.9243\n",
      "Epoch 723/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136853.5625 - mae: 259.8383 - val_loss: 189938.7812 - val_mae: 328.7631\n",
      "Epoch 724/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133658.3906 - mae: 248.3683 - val_loss: 186360.7500 - val_mae: 326.7508\n",
      "Epoch 725/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 132496.7344 - mae: 254.9952 - val_loss: 179752.7656 - val_mae: 321.9727\n",
      "Epoch 726/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 132969.6719 - mae: 256.3834 - val_loss: 185974.0625 - val_mae: 326.7202\n",
      "Epoch 727/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 132591.3906 - mae: 248.4502 - val_loss: 186578.1562 - val_mae: 326.6910\n",
      "Epoch 728/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132496.2656 - mae: 253.2857 - val_loss: 187272.4062 - val_mae: 327.2933\n",
      "Epoch 729/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133134.3906 - mae: 254.3983 - val_loss: 180828.8438 - val_mae: 322.5773\n",
      "Epoch 730/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131886.5000 - mae: 251.1588 - val_loss: 184123.0000 - val_mae: 324.9593\n",
      "Epoch 731/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132415.9375 - mae: 252.4944 - val_loss: 193707.3125 - val_mae: 331.6250\n",
      "Epoch 732/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133422.0312 - mae: 252.1428 - val_loss: 176793.4375 - val_mae: 319.5395\n",
      "Epoch 733/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133044.4688 - mae: 248.7738 - val_loss: 191603.9062 - val_mae: 329.8687\n",
      "Epoch 734/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134083.7344 - mae: 260.4157 - val_loss: 172565.4062 - val_mae: 317.2039\n",
      "Epoch 735/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135925.0156 - mae: 251.7390 - val_loss: 192541.3438 - val_mae: 330.8161\n",
      "Epoch 736/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134132.5312 - mae: 256.3590 - val_loss: 188649.0625 - val_mae: 328.3636\n",
      "Epoch 737/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133649.1875 - mae: 258.3550 - val_loss: 190861.9375 - val_mae: 330.2891\n",
      "Epoch 738/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130888.0312 - mae: 248.1284 - val_loss: 193140.5781 - val_mae: 331.2227\n",
      "Epoch 739/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 131119.8125 - mae: 251.7236 - val_loss: 185118.3125 - val_mae: 325.5511\n",
      "Epoch 740/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131635.0625 - mae: 249.8550 - val_loss: 187614.9375 - val_mae: 327.2513\n",
      "Epoch 741/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 132326.9375 - mae: 247.8729 - val_loss: 182614.9688 - val_mae: 323.8873\n",
      "Epoch 742/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 131957.2344 - mae: 254.3960 - val_loss: 180275.4375 - val_mae: 322.2278\n",
      "Epoch 743/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130457.8594 - mae: 251.6016 - val_loss: 182555.6719 - val_mae: 323.6205\n",
      "Epoch 744/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131215.2344 - mae: 252.2628 - val_loss: 188149.1719 - val_mae: 327.5138\n",
      "Epoch 745/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133760.6875 - mae: 256.3916 - val_loss: 197200.9375 - val_mae: 334.0952\n",
      "Epoch 746/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131226.4375 - mae: 250.7715 - val_loss: 182980.9844 - val_mae: 323.9774\n",
      "Epoch 747/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130644.2500 - mae: 247.1102 - val_loss: 185415.0625 - val_mae: 325.8900\n",
      "Epoch 748/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131246.1562 - mae: 247.1550 - val_loss: 186944.8750 - val_mae: 326.5939\n",
      "Epoch 749/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129964.2891 - mae: 253.9980 - val_loss: 176979.7812 - val_mae: 319.5239\n",
      "Epoch 750/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131781.9688 - mae: 248.2047 - val_loss: 187541.3750 - val_mae: 327.0781\n",
      "Epoch 751/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129710.9688 - mae: 252.8924 - val_loss: 182032.9844 - val_mae: 323.1904\n",
      "Epoch 752/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 131244.7188 - mae: 250.3925 - val_loss: 194573.6875 - val_mae: 331.9805\n",
      "Epoch 753/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128925.5000 - mae: 247.8222 - val_loss: 180303.3125 - val_mae: 321.8518\n",
      "Epoch 754/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129977.5703 - mae: 252.5886 - val_loss: 177883.8906 - val_mae: 319.4167\n",
      "Epoch 755/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131034.1094 - mae: 250.2775 - val_loss: 183467.8281 - val_mae: 323.9328\n",
      "Epoch 756/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129643.1562 - mae: 252.5699 - val_loss: 185525.2500 - val_mae: 325.5195\n",
      "Epoch 757/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130506.9453 - mae: 246.1933 - val_loss: 187190.7656 - val_mae: 326.2826\n",
      "Epoch 758/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 130758.4141 - mae: 252.3068 - val_loss: 191166.0469 - val_mae: 329.5243\n",
      "Epoch 759/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129148.9609 - mae: 249.6079 - val_loss: 184811.7344 - val_mae: 324.5724\n",
      "Epoch 760/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129647.9844 - mae: 253.5427 - val_loss: 186926.4219 - val_mae: 326.2914\n",
      "Epoch 761/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129519.0547 - mae: 247.5721 - val_loss: 195295.7188 - val_mae: 332.4734\n",
      "Epoch 762/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128433.8906 - mae: 246.5745 - val_loss: 185987.4219 - val_mae: 325.7349\n",
      "Epoch 763/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128905.2188 - mae: 251.7451 - val_loss: 182203.2344 - val_mae: 322.5856\n",
      "Epoch 764/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128660.4062 - mae: 247.6558 - val_loss: 193427.5000 - val_mae: 330.8819\n",
      "Epoch 765/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128644.2500 - mae: 246.4946 - val_loss: 187972.9375 - val_mae: 326.8976\n",
      "Epoch 766/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128542.4688 - mae: 250.4161 - val_loss: 182972.5781 - val_mae: 323.2522\n",
      "Epoch 767/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129342.2344 - mae: 252.5577 - val_loss: 193804.2188 - val_mae: 331.1448\n",
      "Epoch 768/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128802.5703 - mae: 245.4508 - val_loss: 188627.2969 - val_mae: 327.5536\n",
      "Epoch 769/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129299.2891 - mae: 247.5445 - val_loss: 185781.6406 - val_mae: 325.3998\n",
      "Epoch 770/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130019.5312 - mae: 256.1263 - val_loss: 185628.4688 - val_mae: 324.9672\n",
      "Epoch 771/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127884.1250 - mae: 248.2584 - val_loss: 190229.6406 - val_mae: 328.3073\n",
      "Epoch 772/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131334.0938 - mae: 243.7086 - val_loss: 194006.3125 - val_mae: 330.7614\n",
      "Epoch 773/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127688.6953 - mae: 251.4188 - val_loss: 179008.1719 - val_mae: 319.9574\n",
      "Epoch 774/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129365.8906 - mae: 257.5777 - val_loss: 192494.2031 - val_mae: 329.8818\n",
      "Epoch 775/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131321.5000 - mae: 244.7587 - val_loss: 194170.8594 - val_mae: 330.9283\n",
      "Epoch 776/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127365.5703 - mae: 248.6810 - val_loss: 183992.0625 - val_mae: 324.0884\n",
      "Epoch 777/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128785.2891 - mae: 246.3520 - val_loss: 195308.6094 - val_mae: 331.8956\n",
      "Epoch 778/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 126328.2891 - mae: 245.7822 - val_loss: 182798.3750 - val_mae: 322.9861\n",
      "Epoch 779/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130070.5391 - mae: 259.0636 - val_loss: 186561.0625 - val_mae: 325.7625\n",
      "Epoch 780/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128979.5000 - mae: 245.0469 - val_loss: 186682.3906 - val_mae: 325.7122\n",
      "Epoch 781/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 126885.1797 - mae: 248.9321 - val_loss: 191214.4531 - val_mae: 328.7285\n",
      "Epoch 782/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127482.8906 - mae: 245.5580 - val_loss: 189379.1875 - val_mae: 327.0063\n",
      "Epoch 783/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127562.3594 - mae: 250.7156 - val_loss: 191917.7188 - val_mae: 329.3073\n",
      "Epoch 784/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127546.3047 - mae: 248.6534 - val_loss: 181332.3125 - val_mae: 321.1754\n",
      "Epoch 785/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 128117.3750 - mae: 246.0239 - val_loss: 191471.6250 - val_mae: 328.3576\n",
      "Epoch 786/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 127222.6562 - mae: 251.6419 - val_loss: 179560.3125 - val_mae: 320.1270\n",
      "Epoch 787/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130225.7812 - mae: 245.6669 - val_loss: 187530.2969 - val_mae: 325.2792\n",
      "Epoch 788/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127302.3438 - mae: 250.1803 - val_loss: 183469.7969 - val_mae: 322.2478\n",
      "Epoch 789/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127693.5703 - mae: 247.4898 - val_loss: 194044.3281 - val_mae: 330.4432\n",
      "Epoch 790/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 126591.0312 - mae: 248.3900 - val_loss: 183700.8906 - val_mae: 322.8512\n",
      "Epoch 791/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127191.1250 - mae: 243.6802 - val_loss: 192290.6719 - val_mae: 328.9674\n",
      "Epoch 792/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125997.8906 - mae: 247.6701 - val_loss: 181800.8438 - val_mae: 321.2477\n",
      "Epoch 793/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127211.2344 - mae: 246.5756 - val_loss: 194263.7031 - val_mae: 330.5061\n",
      "Epoch 794/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126202.1641 - mae: 248.9485 - val_loss: 180944.9531 - val_mae: 320.5621\n",
      "Epoch 795/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126823.5156 - mae: 247.0739 - val_loss: 190377.3125 - val_mae: 327.9061\n",
      "Epoch 796/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127096.8750 - mae: 245.5852 - val_loss: 192009.2344 - val_mae: 328.5548\n",
      "Epoch 797/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125774.6797 - mae: 249.1497 - val_loss: 185008.3438 - val_mae: 323.0626\n",
      "Epoch 798/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127978.7344 - mae: 246.9182 - val_loss: 196922.3906 - val_mae: 332.3538\n",
      "Epoch 799/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129328.1250 - mae: 252.0700 - val_loss: 197992.1719 - val_mae: 333.4002\n",
      "Epoch 800/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125708.3203 - mae: 244.2496 - val_loss: 191410.9375 - val_mae: 327.7526\n",
      "Epoch 801/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127984.0156 - mae: 249.3617 - val_loss: 181903.8438 - val_mae: 321.3647\n",
      "Epoch 802/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124985.2188 - mae: 246.0587 - val_loss: 196827.9219 - val_mae: 332.2725\n",
      "Epoch 803/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 125960.8750 - mae: 248.4832 - val_loss: 187420.8594 - val_mae: 324.9331\n",
      "Epoch 804/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127881.6406 - mae: 245.7766 - val_loss: 183706.3906 - val_mae: 322.2116\n",
      "Epoch 805/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124473.4844 - mae: 246.4861 - val_loss: 190443.4688 - val_mae: 326.7101\n",
      "Epoch 806/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124853.6406 - mae: 243.4886 - val_loss: 193466.0469 - val_mae: 329.1354\n",
      "Epoch 807/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125510.4453 - mae: 246.6619 - val_loss: 186495.1719 - val_mae: 324.2805\n",
      "Epoch 808/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126193.6406 - mae: 246.8723 - val_loss: 184489.8750 - val_mae: 323.0061\n",
      "Epoch 809/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126956.0156 - mae: 245.1436 - val_loss: 186611.0781 - val_mae: 323.8516\n",
      "Epoch 810/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125360.4297 - mae: 246.7918 - val_loss: 185073.2188 - val_mae: 322.6715\n",
      "Epoch 811/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 124269.0156 - mae: 246.3664 - val_loss: 188301.1406 - val_mae: 325.4369\n",
      "Epoch 812/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127233.5703 - mae: 242.8264 - val_loss: 197039.7500 - val_mae: 331.5714\n",
      "Epoch 813/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125761.0547 - mae: 251.9584 - val_loss: 182364.9375 - val_mae: 320.7148\n",
      "Epoch 814/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124104.1094 - mae: 245.3631 - val_loss: 195830.6094 - val_mae: 330.8235\n",
      "Epoch 815/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125342.6250 - mae: 247.2726 - val_loss: 185191.6406 - val_mae: 322.6526\n",
      "Epoch 816/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 125442.5703 - mae: 245.8191 - val_loss: 189319.3750 - val_mae: 325.3963\n",
      "Epoch 817/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124567.3203 - mae: 241.9243 - val_loss: 194111.2969 - val_mae: 328.9241\n",
      "Epoch 818/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 125112.1562 - mae: 247.8652 - val_loss: 189609.8750 - val_mae: 325.5781\n",
      "Epoch 819/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126210.1797 - mae: 250.6282 - val_loss: 189090.5156 - val_mae: 324.9679\n",
      "Epoch 820/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124955.6641 - mae: 243.1803 - val_loss: 188210.8125 - val_mae: 324.6242\n",
      "Epoch 821/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124473.4453 - mae: 242.1488 - val_loss: 191618.2031 - val_mae: 326.8385\n",
      "Epoch 822/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124659.4062 - mae: 251.1618 - val_loss: 189390.4688 - val_mae: 325.4971\n",
      "Epoch 823/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124162.2812 - mae: 242.8489 - val_loss: 198962.4219 - val_mae: 333.0180\n",
      "Epoch 824/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123082.2500 - mae: 242.7216 - val_loss: 188035.8438 - val_mae: 323.9792\n",
      "Epoch 825/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123037.5312 - mae: 245.3911 - val_loss: 185693.0469 - val_mae: 322.3510\n",
      "Epoch 826/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123282.4453 - mae: 247.3563 - val_loss: 188463.0781 - val_mae: 324.3422\n",
      "Epoch 827/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 123494.7891 - mae: 243.6632 - val_loss: 198050.2656 - val_mae: 332.4690\n",
      "Epoch 828/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124333.6406 - mae: 243.3813 - val_loss: 189968.3438 - val_mae: 325.4088\n",
      "Epoch 829/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125501.2188 - mae: 246.5256 - val_loss: 192369.2031 - val_mae: 326.8224\n",
      "Epoch 830/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122927.3438 - mae: 245.9703 - val_loss: 191842.4844 - val_mae: 326.9256\n",
      "Epoch 831/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 125470.4062 - mae: 246.0746 - val_loss: 206372.7500 - val_mae: 338.8891\n",
      "Epoch 832/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121671.2188 - mae: 244.2523 - val_loss: 179207.8750 - val_mae: 317.7429\n",
      "Epoch 833/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123734.5703 - mae: 245.8511 - val_loss: 187067.6562 - val_mae: 322.9434\n",
      "Epoch 834/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 122723.1641 - mae: 245.3352 - val_loss: 188525.3281 - val_mae: 323.7468\n",
      "Epoch 835/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 124480.0938 - mae: 242.9926 - val_loss: 191458.0781 - val_mae: 325.4377\n",
      "Epoch 836/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123183.7188 - mae: 248.7435 - val_loss: 192807.0156 - val_mae: 326.9528\n",
      "Epoch 837/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 123100.3203 - mae: 242.4317 - val_loss: 199291.9688 - val_mae: 332.1997\n",
      "Epoch 838/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123853.2812 - mae: 249.5233 - val_loss: 194011.6094 - val_mae: 327.8547\n",
      "Epoch 839/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121692.7344 - mae: 244.3213 - val_loss: 199777.9844 - val_mae: 332.7868\n",
      "Epoch 840/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123054.0547 - mae: 239.6401 - val_loss: 196501.8281 - val_mae: 329.7793\n",
      "Epoch 841/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122148.6406 - mae: 246.6715 - val_loss: 179753.2500 - val_mae: 316.7861\n",
      "Epoch 842/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124755.8359 - mae: 246.3565 - val_loss: 186626.3125 - val_mae: 321.9823\n",
      "Epoch 843/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121413.6406 - mae: 244.9899 - val_loss: 200702.5312 - val_mae: 333.4915\n",
      "Epoch 844/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124043.9297 - mae: 244.6295 - val_loss: 205513.8906 - val_mae: 337.5778\n",
      "Epoch 845/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123113.0938 - mae: 245.0439 - val_loss: 197316.1719 - val_mae: 330.2772\n",
      "Epoch 846/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124567.1406 - mae: 249.9062 - val_loss: 197903.0938 - val_mae: 331.2828\n",
      "Epoch 847/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122138.0859 - mae: 242.4458 - val_loss: 195520.1094 - val_mae: 329.1004\n",
      "Epoch 848/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121449.7500 - mae: 243.6418 - val_loss: 191627.9531 - val_mae: 325.2272\n",
      "Epoch 849/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121380.2344 - mae: 243.9086 - val_loss: 194515.3281 - val_mae: 327.7196\n",
      "Epoch 850/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121778.1797 - mae: 243.5924 - val_loss: 194221.0156 - val_mae: 327.5791\n",
      "Epoch 851/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121587.9688 - mae: 241.4622 - val_loss: 196215.9062 - val_mae: 329.1938\n",
      "Epoch 852/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120786.4844 - mae: 242.9699 - val_loss: 186315.4688 - val_mae: 320.7182\n",
      "Epoch 853/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121826.5547 - mae: 243.1459 - val_loss: 199157.4375 - val_mae: 331.5017\n",
      "Epoch 854/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121010.9844 - mae: 244.2776 - val_loss: 191211.6250 - val_mae: 324.6817\n",
      "Epoch 855/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120956.9297 - mae: 245.3920 - val_loss: 196970.1719 - val_mae: 329.5230\n",
      "Epoch 856/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120625.2344 - mae: 241.3567 - val_loss: 202244.4375 - val_mae: 334.0657\n",
      "Epoch 857/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120362.4609 - mae: 241.1404 - val_loss: 193727.3438 - val_mae: 326.6266\n",
      "Epoch 858/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122972.2109 - mae: 247.8607 - val_loss: 203623.5312 - val_mae: 335.1002\n",
      "Epoch 859/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123147.5859 - mae: 244.4386 - val_loss: 190853.5625 - val_mae: 324.0668\n",
      "Epoch 860/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120980.4297 - mae: 240.1982 - val_loss: 199859.6406 - val_mae: 331.7219\n",
      "Epoch 861/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120555.9141 - mae: 242.9844 - val_loss: 189362.1094 - val_mae: 322.7247\n",
      "Epoch 862/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120103.7891 - mae: 240.8362 - val_loss: 201388.5312 - val_mae: 332.7407\n",
      "Epoch 863/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121382.9297 - mae: 245.1091 - val_loss: 189675.2812 - val_mae: 323.1693\n",
      "Epoch 864/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120954.9844 - mae: 242.9672 - val_loss: 204266.6719 - val_mae: 335.5757\n",
      "Epoch 865/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120342.6250 - mae: 241.5881 - val_loss: 192362.0781 - val_mae: 324.9996\n",
      "Epoch 866/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120264.7812 - mae: 241.9784 - val_loss: 193231.2969 - val_mae: 325.6383\n",
      "Epoch 867/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119638.8047 - mae: 242.4637 - val_loss: 195236.0781 - val_mae: 327.2184\n",
      "Epoch 868/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120002.3359 - mae: 240.8696 - val_loss: 197598.6562 - val_mae: 329.3190\n",
      "Epoch 869/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119558.3359 - mae: 242.6315 - val_loss: 191812.6406 - val_mae: 324.0991\n",
      "Epoch 870/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 122170.8047 - mae: 241.4955 - val_loss: 187632.2656 - val_mae: 320.4910\n",
      "Epoch 871/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120407.8203 - mae: 243.0923 - val_loss: 185753.9062 - val_mae: 319.0714\n",
      "Epoch 872/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120142.7656 - mae: 247.2515 - val_loss: 197518.7031 - val_mae: 329.2716\n",
      "Epoch 873/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119012.5547 - mae: 239.9223 - val_loss: 198854.6562 - val_mae: 330.3684\n",
      "Epoch 874/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120284.3047 - mae: 240.8984 - val_loss: 206847.9844 - val_mae: 338.1827\n",
      "Epoch 875/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119655.9062 - mae: 242.1262 - val_loss: 187720.9375 - val_mae: 320.7606\n",
      "Epoch 876/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119549.1797 - mae: 241.9166 - val_loss: 194636.4688 - val_mae: 325.9044\n",
      "Epoch 877/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118656.6562 - mae: 240.9593 - val_loss: 195415.8125 - val_mae: 326.6598\n",
      "Epoch 878/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119644.1641 - mae: 240.3006 - val_loss: 187749.8438 - val_mae: 320.1353\n",
      "Epoch 879/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 118666.3438 - mae: 244.4849 - val_loss: 197069.3906 - val_mae: 327.9694\n",
      "Epoch 880/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118521.7500 - mae: 241.4456 - val_loss: 199356.8906 - val_mae: 330.4167\n",
      "Epoch 881/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118551.3594 - mae: 239.9682 - val_loss: 192242.2031 - val_mae: 323.9105\n",
      "Epoch 882/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118895.4609 - mae: 239.8140 - val_loss: 196537.9219 - val_mae: 327.8720\n",
      "Epoch 883/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 118058.0859 - mae: 241.8079 - val_loss: 189516.2500 - val_mae: 321.5414\n",
      "Epoch 884/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119467.7891 - mae: 246.2768 - val_loss: 203131.4219 - val_mae: 332.9248\n",
      "Epoch 885/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119218.6406 - mae: 239.0864 - val_loss: 206151.4219 - val_mae: 337.0594\n",
      "Epoch 886/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119083.5156 - mae: 244.0386 - val_loss: 193817.8281 - val_mae: 324.7995\n",
      "Epoch 887/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119082.2109 - mae: 244.4039 - val_loss: 201093.2188 - val_mae: 331.6055\n",
      "Epoch 888/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122233.9141 - mae: 242.8497 - val_loss: 196168.5625 - val_mae: 327.1071\n",
      "Epoch 889/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122153.3438 - mae: 236.4501 - val_loss: 196328.9219 - val_mae: 327.4379\n",
      "Epoch 890/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118365.3359 - mae: 242.1004 - val_loss: 191328.5625 - val_mae: 322.5808\n",
      "Epoch 891/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120850.3438 - mae: 245.7437 - val_loss: 209351.8750 - val_mae: 339.5881\n",
      "Epoch 892/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117493.1406 - mae: 240.4586 - val_loss: 194419.4375 - val_mae: 325.1815\n",
      "Epoch 893/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117532.9062 - mae: 241.6991 - val_loss: 193241.5000 - val_mae: 323.7787\n",
      "Epoch 894/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118093.8203 - mae: 241.1903 - val_loss: 202489.2031 - val_mae: 333.7859\n",
      "Epoch 895/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117101.4688 - mae: 237.6256 - val_loss: 200993.9375 - val_mae: 331.9777\n",
      "Epoch 896/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117761.7812 - mae: 242.5701 - val_loss: 199193.8438 - val_mae: 330.4249\n",
      "Epoch 897/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119125.6406 - mae: 240.1294 - val_loss: 196975.4688 - val_mae: 327.5816\n",
      "Epoch 898/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118180.5312 - mae: 238.9394 - val_loss: 194125.8594 - val_mae: 325.0097\n",
      "Epoch 899/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 119446.5312 - mae: 244.0917 - val_loss: 214400.5625 - val_mae: 345.0352\n",
      "Epoch 900/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 117938.3594 - mae: 239.2338 - val_loss: 187442.6875 - val_mae: 318.0073\n",
      "Epoch 901/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116796.6953 - mae: 240.6131 - val_loss: 206591.2031 - val_mae: 337.2908\n",
      "Epoch 902/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118716.3906 - mae: 236.8882 - val_loss: 196941.8906 - val_mae: 327.5435\n",
      "Epoch 903/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117554.4609 - mae: 242.5039 - val_loss: 189035.2188 - val_mae: 319.9173\n",
      "Epoch 904/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116996.3203 - mae: 243.1557 - val_loss: 206283.5781 - val_mae: 336.5292\n",
      "Epoch 905/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 117110.8359 - mae: 241.9485 - val_loss: 198025.1250 - val_mae: 328.0996\n",
      "Epoch 906/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116633.7812 - mae: 242.6047 - val_loss: 207083.9375 - val_mae: 337.5153\n",
      "Epoch 907/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119128.1953 - mae: 239.9751 - val_loss: 200046.2188 - val_mae: 330.1405\n",
      "Epoch 908/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116478.9062 - mae: 239.2558 - val_loss: 199847.8281 - val_mae: 330.3084\n",
      "Epoch 909/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117306.2500 - mae: 239.3615 - val_loss: 194789.2500 - val_mae: 325.1594\n",
      "Epoch 910/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115671.0312 - mae: 239.1784 - val_loss: 203079.9375 - val_mae: 333.2242\n",
      "Epoch 911/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115844.1562 - mae: 237.7904 - val_loss: 204524.3594 - val_mae: 334.5843\n",
      "Epoch 912/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117166.1406 - mae: 236.7743 - val_loss: 195955.7031 - val_mae: 326.5761\n",
      "Epoch 913/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117346.3438 - mae: 240.4424 - val_loss: 193307.5938 - val_mae: 323.9324\n",
      "Epoch 914/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115530.7578 - mae: 242.2164 - val_loss: 194756.7500 - val_mae: 324.6122\n",
      "Epoch 915/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115676.0938 - mae: 238.9447 - val_loss: 198163.4375 - val_mae: 327.9980\n",
      "Epoch 916/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115687.7109 - mae: 239.9027 - val_loss: 201665.8750 - val_mae: 332.0127\n",
      "Epoch 917/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115393.7734 - mae: 239.9070 - val_loss: 196754.3906 - val_mae: 326.9893\n",
      "Epoch 918/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114911.4844 - mae: 238.6156 - val_loss: 197673.3438 - val_mae: 327.4803\n",
      "Epoch 919/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115821.5312 - mae: 239.0067 - val_loss: 204316.8594 - val_mae: 334.7955\n",
      "Epoch 920/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117536.7188 - mae: 239.2404 - val_loss: 203566.2812 - val_mae: 333.9991\n",
      "Epoch 921/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114998.7031 - mae: 239.1763 - val_loss: 195694.8281 - val_mae: 325.5276\n",
      "Epoch 922/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115386.9844 - mae: 240.1624 - val_loss: 196826.2188 - val_mae: 327.2459\n",
      "Epoch 923/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114842.8984 - mae: 239.4156 - val_loss: 203828.3906 - val_mae: 334.1051\n",
      "Epoch 924/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115165.2891 - mae: 237.2798 - val_loss: 211120.1875 - val_mae: 341.0452\n",
      "Epoch 925/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115506.1953 - mae: 236.5710 - val_loss: 192804.7500 - val_mae: 322.6813\n",
      "Epoch 926/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115086.9141 - mae: 240.3223 - val_loss: 195559.8125 - val_mae: 325.1891\n",
      "Epoch 927/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114585.2266 - mae: 238.2371 - val_loss: 200689.6875 - val_mae: 330.9465\n",
      "Epoch 928/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114131.6562 - mae: 238.4744 - val_loss: 194382.5625 - val_mae: 324.1756\n",
      "Epoch 929/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114199.5781 - mae: 237.4607 - val_loss: 202161.8906 - val_mae: 331.9064\n",
      "Epoch 930/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115250.7500 - mae: 239.9700 - val_loss: 208396.5000 - val_mae: 337.9863\n",
      "Epoch 931/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114452.0078 - mae: 238.5934 - val_loss: 192210.3594 - val_mae: 322.2917\n",
      "Epoch 932/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115193.1641 - mae: 236.6880 - val_loss: 202831.4531 - val_mae: 332.5883\n",
      "Epoch 933/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 116566.9688 - mae: 244.9529 - val_loss: 193525.4844 - val_mae: 322.5050\n",
      "Epoch 934/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114189.8438 - mae: 236.4119 - val_loss: 205518.5469 - val_mae: 334.3708\n",
      "Epoch 935/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114571.0000 - mae: 235.3310 - val_loss: 201474.9375 - val_mae: 331.8232\n",
      "Epoch 936/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113449.9297 - mae: 239.2755 - val_loss: 199002.4375 - val_mae: 328.2910\n",
      "Epoch 937/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114013.0938 - mae: 237.4430 - val_loss: 200794.2500 - val_mae: 330.7994\n",
      "Epoch 938/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113569.3594 - mae: 237.5928 - val_loss: 200901.9375 - val_mae: 330.1856\n",
      "Epoch 939/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114099.6016 - mae: 240.0715 - val_loss: 209658.6719 - val_mae: 339.0570\n",
      "Epoch 940/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114951.1406 - mae: 236.3399 - val_loss: 200170.5312 - val_mae: 330.3266\n",
      "Epoch 941/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113460.2031 - mae: 241.3664 - val_loss: 193723.0469 - val_mae: 322.6324\n",
      "Epoch 942/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 116059.2812 - mae: 239.4767 - val_loss: 195990.5781 - val_mae: 324.2285\n",
      "Epoch 943/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113657.4766 - mae: 239.8377 - val_loss: 204594.1406 - val_mae: 333.7842\n",
      "Epoch 944/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112760.0312 - mae: 236.5647 - val_loss: 204166.8594 - val_mae: 333.5996\n",
      "Epoch 945/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112863.0234 - mae: 236.0267 - val_loss: 205889.1406 - val_mae: 335.5233\n",
      "Epoch 946/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115412.0078 - mae: 238.0918 - val_loss: 208231.2500 - val_mae: 338.2263\n",
      "Epoch 947/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112286.2812 - mae: 237.4804 - val_loss: 193857.7969 - val_mae: 322.8144\n",
      "Epoch 948/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112805.3203 - mae: 237.8649 - val_loss: 204910.3750 - val_mae: 333.5790\n",
      "Epoch 949/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114095.6953 - mae: 238.1109 - val_loss: 208848.5938 - val_mae: 337.9295\n",
      "Epoch 950/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114188.1719 - mae: 243.1183 - val_loss: 201526.8750 - val_mae: 330.6302\n",
      "Epoch 951/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116142.0703 - mae: 239.5381 - val_loss: 197882.0000 - val_mae: 326.5536\n",
      "Epoch 952/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112256.2734 - mae: 238.7770 - val_loss: 200780.4531 - val_mae: 329.7574\n",
      "Epoch 953/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111817.2188 - mae: 236.8352 - val_loss: 205087.3125 - val_mae: 333.2177\n",
      "Epoch 954/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112836.7891 - mae: 236.0378 - val_loss: 200110.6719 - val_mae: 328.7721\n",
      "Epoch 955/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111841.9609 - mae: 238.3371 - val_loss: 204631.6875 - val_mae: 333.4081\n",
      "Epoch 956/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111314.3047 - mae: 235.2533 - val_loss: 201276.8281 - val_mae: 329.8643\n",
      "Epoch 957/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111556.0469 - mae: 236.1130 - val_loss: 208079.5156 - val_mae: 336.8406\n",
      "Epoch 958/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112014.0859 - mae: 237.8769 - val_loss: 205899.3750 - val_mae: 334.4886\n",
      "Epoch 959/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111300.9531 - mae: 236.0241 - val_loss: 212481.3281 - val_mae: 341.3941\n",
      "Epoch 960/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112026.8438 - mae: 234.3161 - val_loss: 204707.4375 - val_mae: 333.2890\n",
      "Epoch 961/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112170.7578 - mae: 236.0324 - val_loss: 200267.6875 - val_mae: 328.4222\n",
      "Epoch 962/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112880.3828 - mae: 243.4193 - val_loss: 203807.0938 - val_mae: 332.5744\n",
      "Epoch 963/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113456.6562 - mae: 234.7925 - val_loss: 204022.9375 - val_mae: 332.7315\n",
      "Epoch 964/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113096.9297 - mae: 242.4415 - val_loss: 204004.5625 - val_mae: 332.6058\n",
      "Epoch 965/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111057.1328 - mae: 236.1346 - val_loss: 219602.5000 - val_mae: 349.4743\n",
      "Epoch 966/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112359.7266 - mae: 233.4747 - val_loss: 196813.0156 - val_mae: 325.1355\n",
      "Epoch 967/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111563.1250 - mae: 237.3575 - val_loss: 204334.7344 - val_mae: 332.9556\n",
      "Epoch 968/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110150.8516 - mae: 235.0248 - val_loss: 208570.2812 - val_mae: 336.6858\n",
      "Epoch 969/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113283.3672 - mae: 238.0175 - val_loss: 197333.8750 - val_mae: 324.7789\n",
      "Epoch 970/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109992.7969 - mae: 236.4096 - val_loss: 209009.1250 - val_mae: 337.6175\n",
      "Epoch 971/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110404.8203 - mae: 234.3707 - val_loss: 210097.3906 - val_mae: 338.8814\n",
      "Epoch 972/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109711.8438 - mae: 236.9784 - val_loss: 203064.3125 - val_mae: 330.5250\n",
      "Epoch 973/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 110178.1953 - mae: 234.2075 - val_loss: 202892.7969 - val_mae: 330.9730\n",
      "Epoch 974/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109964.5938 - mae: 237.8705 - val_loss: 207592.7969 - val_mae: 335.4373\n",
      "Epoch 975/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110982.2031 - mae: 236.6895 - val_loss: 204554.1094 - val_mae: 333.1696\n",
      "Epoch 976/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110276.5234 - mae: 234.5439 - val_loss: 211142.1875 - val_mae: 340.6975\n",
      "Epoch 977/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111889.0156 - mae: 239.6053 - val_loss: 211377.5625 - val_mae: 339.0702\n",
      "Epoch 978/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109692.6797 - mae: 234.2926 - val_loss: 219366.8125 - val_mae: 348.1207\n",
      "Epoch 979/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109663.6953 - mae: 234.3304 - val_loss: 198126.5625 - val_mae: 325.4663\n",
      "Epoch 980/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110116.5234 - mae: 236.1292 - val_loss: 211506.6875 - val_mae: 340.8528\n",
      "Epoch 981/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 110099.8281 - mae: 236.6361 - val_loss: 206335.1094 - val_mae: 334.3755\n",
      "Epoch 982/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109825.0156 - mae: 234.8544 - val_loss: 202099.1094 - val_mae: 329.4092\n",
      "Epoch 983/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108848.8906 - mae: 236.5508 - val_loss: 216101.9375 - val_mae: 345.3048\n",
      "Epoch 984/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108925.1406 - mae: 233.2197 - val_loss: 207944.1719 - val_mae: 336.0461\n",
      "Epoch 985/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109102.0703 - mae: 234.9973 - val_loss: 206585.7188 - val_mae: 334.4654\n",
      "Epoch 986/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109763.9688 - mae: 236.5977 - val_loss: 217633.2031 - val_mae: 346.6535\n",
      "Epoch 987/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109332.5156 - mae: 231.7648 - val_loss: 210074.9688 - val_mae: 337.6208\n",
      "Epoch 988/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109704.4062 - mae: 239.3651 - val_loss: 209615.9375 - val_mae: 336.6639\n",
      "Epoch 989/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112329.1172 - mae: 234.3474 - val_loss: 213007.7500 - val_mae: 339.9758\n",
      "Epoch 990/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108961.4141 - mae: 238.5468 - val_loss: 202284.5156 - val_mae: 328.8638\n",
      "Epoch 991/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108844.4062 - mae: 235.8814 - val_loss: 212745.2031 - val_mae: 340.6375\n",
      "Epoch 992/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109635.4297 - mae: 232.7310 - val_loss: 209012.0469 - val_mae: 337.1794\n",
      "Epoch 993/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 112945.5312 - mae: 238.9269 - val_loss: 211818.7344 - val_mae: 340.3804\n",
      "Epoch 994/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108430.0469 - mae: 238.6022 - val_loss: 211087.9844 - val_mae: 337.7191\n",
      "Epoch 995/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107962.6406 - mae: 235.7217 - val_loss: 224045.0625 - val_mae: 351.8769\n",
      "Epoch 996/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107931.2266 - mae: 231.4379 - val_loss: 217346.4375 - val_mae: 345.4268\n",
      "Epoch 997/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 109590.5938 - mae: 238.7207 - val_loss: 214026.6875 - val_mae: 342.4595\n",
      "Epoch 998/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109346.7578 - mae: 236.1387 - val_loss: 207902.5156 - val_mae: 335.3766\n",
      "Epoch 999/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109262.9141 - mae: 236.8067 - val_loss: 224098.9531 - val_mae: 351.6364\n",
      "Epoch 1000/1000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 108991.6719 - mae: 234.8407 - val_loss: 207070.0156 - val_mae: 333.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22cb342c290>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y, epochs=1000, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c4205-253d-4b67-986c-f3e6791ac9a2",
   "metadata": {},
   "source": [
    "**Passo 10** - Vamos agora avaliar os resultados na base de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ef373a0-c962-48f1-a21f-b73c8cd6cdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Manufacturer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Screen",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPU",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OS",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CPU_core",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Screen_Size_cm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CPU_frequency",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RAM_GB",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Storage_GB_SSD",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Weight_kg",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "91784b43-ca69-47cd-9ec4-00634a9cfab3",
       "rows": [
        [
         "0",
         "Dell",
         "3",
         "Full HD",
         "1",
         "1",
         "7",
         "39.624",
         "2.7",
         "16",
         "256",
         "2.3"
        ],
        [
         "1",
         "Acer",
         "3",
         "IPS Panel",
         "2",
         "1",
         "3",
         "35.56",
         "2.4",
         "4",
         "128",
         "1.8"
        ],
        [
         "2",
         "Dell",
         "1",
         "Full HD",
         "3",
         "1",
         "5",
         "39.624",
         "2.5",
         "8",
         "256",
         "2.62"
        ],
        [
         "3",
         "Dell",
         "3",
         "Full HD",
         "1",
         "1",
         "3",
         "39.624",
         "2.0",
         "8",
         "256",
         "2.0"
        ],
        [
         "4",
         "HP",
         "5",
         "Full HD",
         "3",
         "1",
         "7",
         "39.624",
         "2.8",
         "8",
         "256",
         "3.14"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Category</th>\n",
       "      <th>Screen</th>\n",
       "      <th>GPU</th>\n",
       "      <th>OS</th>\n",
       "      <th>CPU_core</th>\n",
       "      <th>Screen_Size_cm</th>\n",
       "      <th>CPU_frequency</th>\n",
       "      <th>RAM_GB</th>\n",
       "      <th>Storage_GB_SSD</th>\n",
       "      <th>Weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell</td>\n",
       "      <td>3</td>\n",
       "      <td>Full HD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39.624</td>\n",
       "      <td>2.7</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer</td>\n",
       "      <td>3</td>\n",
       "      <td>IPS Panel</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35.560</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell</td>\n",
       "      <td>1</td>\n",
       "      <td>Full HD</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>39.624</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell</td>\n",
       "      <td>3</td>\n",
       "      <td>Full HD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP</td>\n",
       "      <td>5</td>\n",
       "      <td>Full HD</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39.624</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer  Category     Screen  GPU  OS  CPU_core  Screen_Size_cm  \\\n",
       "0         Dell         3    Full HD    1   1         7          39.624   \n",
       "1         Acer         3  IPS Panel    2   1         3          35.560   \n",
       "2         Dell         1    Full HD    3   1         5          39.624   \n",
       "3         Dell         3    Full HD    1   1         3          39.624   \n",
       "4           HP         5    Full HD    3   1         7          39.624   \n",
       "\n",
       "   CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  \n",
       "0            2.7      16             256       2.30  \n",
       "1            2.4       4             128       1.80  \n",
       "2            2.5       8             256       2.62  \n",
       "3            2.0       8             256       2.00  \n",
       "4            2.8       8             256       3.14  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazer previsões com base no modelo\n",
    "laptop_test = pd.read_csv('C:/Users/RH_VG/Downloads/laptop_pricing_NN_teste.csv')\n",
    "laptop_test.head()\n",
    "\n",
    "#predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c2294232-f5cd-439e-80d5-b45738351340",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[129]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m results_model = X_test.copy()\n\u001b[32m      5\u001b[39m results_model[\u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m] = y_test\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m results_model[\u001b[33m'\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpredictions\u001b[49m\n\u001b[32m      9\u001b[39m results_model[\u001b[33m'\u001b[39m\u001b[33mError\u001b[39m\u001b[33m'\u001b[39m] = results_model[\u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m] - results_model[\u001b[33m'\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m'\u001b[39m] \n\u001b[32m     11\u001b[39m results_model\n",
      "\u001b[31mNameError\u001b[39m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Comprar previsões com valores reais\n",
    "\n",
    "results_model = X_test.copy()\n",
    "\n",
    "results_model['Price'] = y_test\n",
    "\n",
    "results_model['Predicted'] = predictions\n",
    "\n",
    "results_model['Error'] = results_model['Price'] - results_model['Predicted'] \n",
    "\n",
    "results_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca1defc-66af-4cb4-a356-fa9952eff0ca",
   "metadata": {},
   "source": [
    "**Passo 11** - Guardar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab359ecb-8202-4aa5-bd6e-10a9f4e4477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/RH_VG/Downloads/my_keras_nn_model.keras')  # or use .keras format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
